{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9833038,"sourceType":"datasetVersion","datasetId":6031130}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.model_selection import GridSearchCV\nfrom torchvision import models, transforms\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import ImageFolder\nimport torch\n\n# Paths to your dataset\ntrain_dir = '/kaggle/input/disasterclassification/train'\nval_dir = '/kaggle/input/disasterclassification/validation'\n\n# Define image transformations\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),  # Resize to ResNet input size\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # ResNet normalization\n])\n\n# Load datasets\ntrain_dataset = ImageFolder(train_dir, transform=transform)\nval_dataset = ImageFolder(val_dir, transform=transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\n# Load pre-trained ResNet model (feature extractor)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nresnet = models.resnet18(pretrained=True)\nresnet = torch.nn.Sequential(*(list(resnet.children())[:-1]))  # Remove classification head\nresnet.to(device)\nresnet.eval()\n\n# Function to extract features\ndef extract_features(dataloader, model):\n    features, labels = [], []\n    with torch.no_grad():\n        for images, label_batch in dataloader:\n            images = images.to(device)\n            outputs = model(images)\n            outputs = outputs.view(outputs.size(0), -1)  # Flatten the features\n            features.append(outputs.cpu().numpy())\n            labels.append(label_batch.numpy())\n    return np.vstack(features), np.hstack(labels)\n\n# Extract features from train and validation sets\nprint(\"Extracting features...\")\ntrain_features, train_labels = extract_features(train_loader, resnet)\nval_features, val_labels = extract_features(val_loader, resnet)\n\n# Hyperparameter tuning for kNN\nprint(\"Tuning kNN hyperparameters...\")\nparam_grid = {'n_neighbors': [ 7, 9,11], 'weights': ['uniform', 'distance']}\nknn = KNeighborsClassifier()\ngrid_search = GridSearchCV(knn, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\ngrid_search.fit(train_features, train_labels)\n\n# Best parameters and validation performance\nprint(f\"Best Parameters: {grid_search.best_params_}\")\nbest_knn = grid_search.best_estimator_\nval_predictions = best_knn.predict(val_features)\n\nprint(\"Validation Accuracy:\", accuracy_score(val_labels, val_predictions))\nprint(\"Classification Report:\")\nprint(classification_report(val_labels, val_predictions, target_names=train_dataset.classes))\n\n# Optionally, save the best model\n# import joblib\n# joblib.dump(best_knn, \"best_knn_model.pkl\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T04:31:59.238489Z","iopub.execute_input":"2024-11-24T04:31:59.238924Z","iopub.status.idle":"2024-11-24T04:34:41.381680Z","shell.execute_reply.started":"2024-11-24T04:31:59.238889Z","shell.execute_reply":"2024-11-24T04:34:41.380619Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Extracting features...\nTuning kNN hyperparameters...\nBest Parameters: {'n_neighbors': 9, 'weights': 'distance'}\nValidation Accuracy: 0.9625\nClassification Report:\n              precision    recall  f1-score   support\n\n     cyclone       0.97      0.99      0.98       100\n  earthquake       0.97      0.97      0.97       100\n       flood       0.97      0.93      0.95       100\n    wildfire       0.94      0.96      0.95       100\n\n    accuracy                           0.96       400\n   macro avg       0.96      0.96      0.96       400\nweighted avg       0.96      0.96      0.96       400\n\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from sklearn.metrics import classification_report, accuracy_score\n\n# Classification Report for Training Set\ntrain_predictions = best_knn.predict(train_features)\n\nprint(\"\\nTraining Accuracy:\", accuracy_score(train_labels, train_predictions))\nprint(\"\\nTraining Classification Report:\")\nprint(classification_report(train_labels, train_predictions, target_names=train_dataset.classes))\n\n# Classification Report for Validation Set\nval_predictions = best_knn.predict(val_features)\n\nprint(\"\\nValidation Accuracy:\", accuracy_score(val_labels, val_predictions))\nprint(\"\\nValidation Classification Report:\")\nprint(classification_report(val_labels, val_predictions, target_names=train_dataset.classes))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T04:28:19.053207Z","iopub.execute_input":"2024-11-24T04:28:19.054001Z","iopub.status.idle":"2024-11-24T04:28:19.185881Z","shell.execute_reply.started":"2024-11-24T04:28:19.053948Z","shell.execute_reply":"2024-11-24T04:28:19.183278Z"}},"outputs":[{"name":"stdout","text":"\nTraining Accuracy: 1.0\n\nTraining Classification Report:\n              precision    recall  f1-score   support\n\n     cyclone       1.00      1.00      1.00       400\n  earthquake       1.00      1.00      1.00       400\n       flood       1.00      1.00      1.00       400\n    wildfire       1.00      1.00      1.00       400\n\n    accuracy                           1.00      1600\n   macro avg       1.00      1.00      1.00      1600\nweighted avg       1.00      1.00      1.00      1600\n\n\nValidation Accuracy: 0.9625\n\nValidation Classification Report:\n              precision    recall  f1-score   support\n\n     cyclone       0.97      0.99      0.98       100\n  earthquake       0.97      0.97      0.97       100\n       flood       0.97      0.93      0.95       100\n    wildfire       0.94      0.96      0.95       100\n\n    accuracy                           0.96       400\n   macro avg       0.96      0.96      0.96       400\nweighted avg       0.96      0.96      0.96       400\n\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.model_selection import GridSearchCV\nfrom PIL import Image\n\n# Paths to your dataset\ntrain_dir = '/kaggle/input/disasterclassification/train'\nval_dir = '/kaggle/input/disasterclassification/validation'\n\n# Image preprocessing: Resize images to a smaller size (e.g., 64x64) for simplicity\ndef load_images_from_folder(folder):\n    images = []\n    labels = []\n    classes = sorted(os.listdir(folder))  # Assumes subfolders are class names\n    for idx, class_name in enumerate(classes):\n        class_path = os.path.join(folder, class_name)\n        if os.path.isdir(class_path):\n            for image_name in os.listdir(class_path):\n                image_path = os.path.join(class_path, image_name)\n                try:\n                    # Load image, resize, and flatten into a 1D array\n                    img = Image.open(image_path).resize((64, 64))\n                    img_array = np.array(img).flatten()\n                    images.append(img_array)\n                    labels.append(idx)\n                except Exception as e:\n                    print(f\"Error loading image {image_path}: {e}\")\n    return np.array(images), np.array(labels), classes\n\n# Load train and validation datasets\nprint(\"Loading training data...\")\ntrain_features, train_labels, class_names = load_images_from_folder(train_dir)\n\nprint(\"Loading validation data...\")\nval_features, val_labels, _ = load_images_from_folder(val_dir)\n\n# Normalize features to [0, 1] range\ntrain_features = train_features / 255.0\nval_features = val_features / 255.0\n\n# Hyperparameter tuning for kNN\nprint(\"Tuning kNN hyperparameters...\")\nparam_grid = {'n_neighbors': [3, 4,5,6, 7, 9, 15,20], 'weights': ['uniform', 'distance']}\nknn = KNeighborsClassifier()\ngrid_search = GridSearchCV(knn, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\ngrid_search.fit(train_features, train_labels)\n\n# Best parameters and validation performance\nprint(f\"Best Parameters: {grid_search.best_params_}\")\nbest_knn = grid_search.best_estimator_\n\n# Training performance\ntrain_predictions = best_knn.predict(train_features)\nprint(\"\\nTraining Accuracy:\", accuracy_score(train_labels, train_predictions))\nprint(\"\\nTraining Classification Report:\")\nprint(classification_report(train_labels, train_predictions, target_names=class_names))\n\n# Validation performance\nval_predictions = best_knn.predict(val_features)\nprint(\"\\nValidation Accuracy:\", accuracy_score(val_labels, val_predictions))\nprint(\"\\nValidation Classification Report:\")\nprint(classification_report(val_labels, val_predictions, target_names=class_names))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T04:53:02.720062Z","iopub.execute_input":"2024-11-24T04:53:02.720443Z","iopub.status.idle":"2024-11-24T04:54:18.493540Z","shell.execute_reply.started":"2024-11-24T04:53:02.720410Z","shell.execute_reply":"2024-11-24T04:54:18.492507Z"}},"outputs":[{"name":"stdout","text":"Loading training data...\nLoading validation data...\nTuning kNN hyperparameters...\nBest Parameters: {'n_neighbors': 5, 'weights': 'distance'}\n\nTraining Accuracy: 1.0\n\nTraining Classification Report:\n              precision    recall  f1-score   support\n\n     cyclone       1.00      1.00      1.00       400\n  earthquake       1.00      1.00      1.00       400\n       flood       1.00      1.00      1.00       400\n    wildfire       1.00      1.00      1.00       400\n\n    accuracy                           1.00      1600\n   macro avg       1.00      1.00      1.00      1600\nweighted avg       1.00      1.00      1.00      1600\n\n\nValidation Accuracy: 0.48\n\nValidation Classification Report:\n              precision    recall  f1-score   support\n\n     cyclone       0.96      0.43      0.59       100\n  earthquake       0.42      0.05      0.09       100\n       flood       0.41      0.54      0.47       100\n    wildfire       0.43      0.90      0.58       100\n\n    accuracy                           0.48       400\n   macro avg       0.55      0.48      0.43       400\nweighted avg       0.55      0.48      0.43       400\n\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.model_selection import GridSearchCV\nfrom PIL import Image\nimport os\nimport numpy as np\n\n# Paths to your dataset\ntrain_dir = '/kaggle/input/disasterclassification/train'\nval_dir = '/kaggle/input/disasterclassification/validation'\n\n# Image preprocessing: Resize images to a smaller size (e.g., 64x64) for simplicity\ndef load_images_from_folder(folder):\n    images = []\n    labels = []\n    classes = sorted(os.listdir(folder))  # Assumes subfolders are class names\n    for idx, class_name in enumerate(classes):\n        class_path = os.path.join(folder, class_name)\n        if os.path.isdir(class_path):\n            for image_name in os.listdir(class_path):\n                image_path = os.path.join(class_path, image_name)\n                try:\n                    # Load image, resize, and flatten into a 1D array\n                    img = Image.open(image_path).resize((64, 64))\n                    img_array = np.array(img).flatten()\n                    images.append(img_array)\n                    labels.append(idx)\n                except Exception as e:\n                    print(f\"Error loading image {image_path}: {e}\")\n    return np.array(images), np.array(labels), classes\n\n# Load train and validation datasets\nprint(\"Loading training data...\")\ntrain_features, train_labels, class_names = load_images_from_folder(train_dir)\n\nprint(\"Loading validation data...\")\nval_features, val_labels, _ = load_images_from_folder(val_dir)\n\n# Normalize features to [0, 1] range\ntrain_features = train_features / 255.0\nval_features = val_features / 255.0\n\n# Apply LDA\nprint(\"Applying LDA for dimensionality reduction...\")\nlda = LinearDiscriminantAnalysis(n_components=3)  # Max components for 4 classes is 3\ntrain_features_lda = lda.fit_transform(train_features, train_labels)\nval_features_lda = lda.transform(val_features)\n\n# Hyperparameter tuning for kNN\nprint(\"Tuning kNN hyperparameters...\")\nparam_grid = {'n_neighbors': [1, 3, 5, 7, 9], 'weights': ['uniform', 'distance']}\nknn = KNeighborsClassifier()\ngrid_search = GridSearchCV(knn, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\ngrid_search.fit(train_features_lda, train_labels)\n\n# Best parameters and validation performance\nprint(f\"Best Parameters: {grid_search.best_params_}\")\nbest_knn = grid_search.best_estimator_\n\n# Training performance\ntrain_predictions = best_knn.predict(train_features_lda)\nprint(\"\\nTraining Accuracy:\", accuracy_score(train_labels, train_predictions))\nprint(\"\\nTraining Classification Report:\")\nprint(classification_report(train_labels, train_predictions, target_names=class_names))\n\n# Validation performance\nval_predictions = best_knn.predict(val_features_lda)\nprint(\"\\nValidation Accuracy:\", accuracy_score(val_labels, val_predictions))\nprint(\"\\nValidation Classification Report:\")\nprint(classification_report(val_labels, val_predictions, target_names=class_names))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T04:58:15.736354Z","iopub.execute_input":"2024-11-24T04:58:15.737181Z","iopub.status.idle":"2024-11-24T04:59:14.846449Z","shell.execute_reply.started":"2024-11-24T04:58:15.737140Z","shell.execute_reply":"2024-11-24T04:59:14.844894Z"}},"outputs":[{"name":"stdout","text":"Loading training data...\nLoading validation data...\nApplying LDA for dimensionality reduction...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApplying LDA for dimensionality reduction...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     46\u001b[0m lda \u001b[38;5;241m=\u001b[39m LinearDiscriminantAnalysis(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)  \u001b[38;5;66;03m# Max components for 4 classes is 3\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m train_features_lda \u001b[38;5;241m=\u001b[39m \u001b[43mlda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m val_features_lda \u001b[38;5;241m=\u001b[39m lda\u001b[38;5;241m.\u001b[39mtransform(val_features)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Hyperparameter tuning for kNN\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/base.py:881\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m--> 881\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:608\u001b[0m, in \u001b[0;36mLinearDiscriminantAnalysis.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components \u001b[38;5;241m>\u001b[39m max_components:\n\u001b[0;32m--> 608\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    609\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_components cannot be larger than min(n_features, n_classes - 1).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    610\u001b[0m         )\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_components \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n","\u001b[0;31mValueError\u001b[0m: n_components cannot be larger than min(n_features, n_classes - 1)."],"ename":"ValueError","evalue":"n_components cannot be larger than min(n_features, n_classes - 1).","output_type":"error"}],"execution_count":8},{"cell_type":"code","source":"from sklearn.decomposition import PCA\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.model_selection import GridSearchCV\nfrom PIL import Image\nimport os\nimport numpy as np\n\n\n# Image preprocessing: Resize images to a smaller size (e.g., 64x64) for simplicity\ndef load_images_from_folder(folder):\n    images = []\n    labels = []\n    classes = sorted(os.listdir(folder))  # Assumes subfolders are class names\n    for idx, class_name in enumerate(classes):\n        class_path = os.path.join(folder, class_name)\n        if os.path.isdir(class_path):\n            for image_name in os.listdir(class_path):\n                image_path = os.path.join(class_path, image_name)\n                try:\n                    # Load image, resize, and flatten into a 1D array\n                    img = Image.open(image_path).resize((128, 128))\n                    img_array = np.array(img).flatten()\n                    images.append(img_array)\n                    labels.append(idx)\n                except Exception as e:\n                    print(f\"Error loading image {image_path}: {e}\")\n    return np.array(images), np.array(labels), classes\n\n# Load train and validation datasets\nprint(\"Loading training data...\")\ntrain_features, train_labels, class_names = load_images_from_folder(train_dir)\n\nprint(\"Loading validation data...\")\nval_features, val_labels, _ = load_images_from_folder(val_dir)\n\n# Normalize features to [0, 1] range\ntrain_features = train_features / 255.0\nval_features = val_features / 255.0\n\n# Apply PCA for dimensionality reduction\nprint(\"Applying PCA for dimensionality reduction...\")\npca = PCA(n_components=70)  # Adjust the number of components as needed\ntrain_features_pca = pca.fit_transform(train_features)\nval_features_pca = pca.transform(val_features)\n\n# Hyperparameter tuning for kNN\nprint(\"Tuning kNN hyperparameters...\")\nparam_grid = {'n_neighbors': [3, 5, 7, 9, 11, 15], 'weights': ['uniform', 'distance']}\nknn = KNeighborsClassifier()\ngrid_search = GridSearchCV(knn, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\ngrid_search.fit(train_features_pca, train_labels)\n\n# Best parameters and validation performance\nprint(f\"Best Parameters: {grid_search.best_params_}\")\nbest_knn = grid_search.best_estimator_\n\n# Training performance\ntrain_predictions = best_knn.predict(train_features_pca)\nprint(\"\\nTraining Accuracy:\", accuracy_score(train_labels, train_predictions))\nprint(\"\\nTraining Classification Report:\")\nprint(classification_report(train_labels, train_predictions, target_names=class_names))\n\n# Validation performance\nval_predictions = best_knn.predict(val_features_pca)\nprint(\"\\nValidation Accuracy:\", accuracy_score(val_labels, val_predictions))\nprint(\"\\nValidation Classification Report:\")\nprint(classification_report(val_labels, val_predictions, target_names=class_names))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T05:23:52.309344Z","iopub.execute_input":"2024-11-24T05:23:52.309873Z","iopub.status.idle":"2024-11-24T05:25:04.349216Z","shell.execute_reply.started":"2024-11-24T05:23:52.309830Z","shell.execute_reply":"2024-11-24T05:25:04.347364Z"}},"outputs":[{"name":"stdout","text":"Loading training data...\nLoading validation data...\nApplying PCA for dimensionality reduction...\nTuning kNN hyperparameters...\nBest Parameters: {'n_neighbors': 7, 'weights': 'distance'}\n\nTraining Accuracy: 1.0\n\nTraining Classification Report:\n              precision    recall  f1-score   support\n\n     cyclone       1.00      1.00      1.00       400\n  earthquake       1.00      1.00      1.00       400\n       flood       1.00      1.00      1.00       400\n    wildfire       1.00      1.00      1.00       400\n\n    accuracy                           1.00      1600\n   macro avg       1.00      1.00      1.00      1600\nweighted avg       1.00      1.00      1.00      1600\n\n\nValidation Accuracy: 0.6\n\nValidation Classification Report:\n              precision    recall  f1-score   support\n\n     cyclone       0.98      0.50      0.66       100\n  earthquake       0.52      0.25      0.34       100\n       flood       0.49      0.78      0.60       100\n    wildfire       0.62      0.87      0.72       100\n\n    accuracy                           0.60       400\n   macro avg       0.65      0.60      0.58       400\nweighted avg       0.65      0.60      0.58       400\n\n","output_type":"stream"}],"execution_count":11}]}