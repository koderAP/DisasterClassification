{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9833038,"sourceType":"datasetVersion","datasetId":6031130}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport os\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T01:11:43.933749Z","iopub.execute_input":"2024-11-22T01:11:43.934130Z","iopub.status.idle":"2024-11-22T01:11:59.512723Z","shell.execute_reply.started":"2024-11-22T01:11:43.934096Z","shell.execute_reply":"2024-11-22T01:11:59.511568Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Load images and labels\ndef load_images_and_labels(image_dir, classes, img_size):\n    images = []\n    labels = []\n    for label, cls in enumerate(classes):\n        class_dir = os.path.join(image_dir, cls)\n        for img_file in os.listdir(class_dir):\n            img_path = os.path.join(class_dir, img_file)\n            try:\n                img = load_img(img_path, target_size=img_size)\n                img_array = img_to_array(img)\n                images.append(img_array)\n                labels.append(label)\n            except Exception as e:\n                print(f\"Error loading image {img_file}: {e}\")\n    return np.array(images), np.array(labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T01:11:59.514452Z","iopub.execute_input":"2024-11-22T01:11:59.514987Z","iopub.status.idle":"2024-11-22T01:11:59.523107Z","shell.execute_reply.started":"2024-11-22T01:11:59.514955Z","shell.execute_reply":"2024-11-22T01:11:59.522111Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Load and preprocess training and validation data\ntrain_folder = '/kaggle/input/disasterclassification/train'\nval_folder = '/kaggle/input/disasterclassification/validation'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T01:11:59.524464Z","iopub.execute_input":"2024-11-22T01:11:59.524870Z","iopub.status.idle":"2024-11-22T01:11:59.543656Z","shell.execute_reply.started":"2024-11-22T01:11:59.524827Z","shell.execute_reply":"2024-11-22T01:11:59.542606Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"classes = ['earthquake', 'cyclone', 'flood', 'wildfire']\nimg_size = (224, 224)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T01:11:59.545770Z","iopub.execute_input":"2024-11-22T01:11:59.546105Z","iopub.status.idle":"2024-11-22T01:11:59.557730Z","shell.execute_reply.started":"2024-11-22T01:11:59.546074Z","shell.execute_reply":"2024-11-22T01:11:59.556765Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"print(\"Loading images...\")\ntrain_images, y_train = load_images_and_labels(train_folder, classes, img_size)\nval_images, y_val = load_images_and_labels(val_folder, classes, img_size)\n\n# Preprocess images for VGG16\ntrain_images = preprocess_input(train_images)\nval_images = preprocess_input(val_images)\n\n# Extract features using VGG16\nprint(\"Extracting features...\")\nvgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\ntrain_features = vgg_model.predict(train_images)\nval_features = vgg_model.predict(val_images)\nX_train = train_features.reshape(train_features.shape[0], -1)  # Flatten features\nX_val = val_features.reshape(val_features.shape[0],-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T01:11:59.558975Z","iopub.execute_input":"2024-11-22T01:11:59.559312Z","iopub.status.idle":"2024-11-22T01:22:21.196758Z","shell.execute_reply.started":"2024-11-22T01:11:59.559274Z","shell.execute_reply":"2024-11-22T01:22:21.195456Z"}},"outputs":[{"name":"stdout","text":"Loading images...\nExtracting features...\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m452s\u001b[0m 9s/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 9s/step\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"print(\"Training Bagging Classifier...\")\nbagging_model = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42)\nbagging_model.fit(X_train, y_train)\n\ny_pred = bagging_model.predict(X_val)\nprint(\"Classification Report:\")\nprint(classification_report(y_val, y_pred, target_names=classes))\nprint(f\"Accuracy: {accuracy_score(y_val, y_pred):.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T01:22:21.198655Z","iopub.execute_input":"2024-11-22T01:22:21.199121Z","iopub.status.idle":"2024-11-22T01:30:38.276648Z","shell.execute_reply.started":"2024-11-22T01:22:21.199072Z","shell.execute_reply":"2024-11-22T01:30:38.275522Z"}},"outputs":[{"name":"stdout","text":"Training Bagging Classifier...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Classification Report:\n              precision    recall  f1-score   support\n\n  earthquake       0.90      0.94      0.92       100\n     cyclone       0.93      0.93      0.93       100\n       flood       0.96      0.92      0.94       100\n    wildfire       0.90      0.90      0.90       100\n\n    accuracy                           0.92       400\n   macro avg       0.92      0.92      0.92       400\nweighted avg       0.92      0.92      0.92       400\n\nAccuracy: 0.92\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import numpy as np\nimport os\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\n\n# Train AdaBoost Classifier\nprint(\"Training AdaBoost Classifier...\")\nbase_learner = DecisionTreeClassifier(max_depth=1)  # Weak learner\nboosting_model = AdaBoostClassifier(base_estimator=base_learner, n_estimators=150, learning_rate=0.1, random_state=42)\nboosting_model.fit(X_train, y_train)\n\n# Evaluate the model\ny_pred = boosting_model.predict(X_val)\nprint(\"Classification Report:\")\nprint(classification_report(y_val, y_pred, target_names=classes))\nprint(f\"Accuracy: {accuracy_score(y_val, y_pred):.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T01:30:38.278114Z","iopub.execute_input":"2024-11-22T01:30:38.279209Z","iopub.status.idle":"2024-11-22T01:34:28.195188Z","shell.execute_reply.started":"2024-11-22T01:30:38.279172Z","shell.execute_reply":"2024-11-22T01:34:28.193221Z"}},"outputs":[{"name":"stdout","text":"Training AdaBoost Classifier...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Classification Report:\n              precision    recall  f1-score   support\n\n  earthquake       0.99      0.76      0.86       100\n     cyclone       0.99      0.91      0.95       100\n       flood       0.80      0.96      0.87       100\n    wildfire       0.86      0.96      0.91       100\n\n    accuracy                           0.90       400\n   macro avg       0.91      0.90      0.90       400\nweighted avg       0.91      0.90      0.90       400\n\nAccuracy: 0.90\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\nimport numpy as np\nfrom itertools import product\n\ndef grid_search(X_train, y_train, X_val, y_val, param_grid):\n    \"\"\"\n    Perform grid search to find the best hyperparameters for AdaBoost.\n\n    Args:\n        X_train: Features for training.\n        y_train: Labels for training.\n        X_val: Features for validation.\n        y_val: Labels for validation.\n        param_grid: Dictionary of hyperparameters and their values to search.\n\n    Returns:\n        best_params: Dictionary of the best parameters.\n        best_model: The best AdaBoost model trained with the best parameters.\n        best_score: The highest validation accuracy.\n    \"\"\"\n    best_score = 0\n    best_params = None\n    best_model = None\n\n    # Generate all combinations of hyperparameters\n    keys, values = zip(*param_grid.items())\n    for param_combination in product(*values):\n        params = dict(zip(keys, param_combination))\n\n        print(params)\n        # Initialize AdaBoost with the current set of parameters\n        base_learner = DecisionTreeClassifier(max_depth=params['max_depth'])\n        model = AdaBoostClassifier(\n            estimator=base_learner,\n            n_estimators=params['n_estimators'],\n            learning_rate=params['learning_rate'],\n            random_state=42\n        )\n        \n        # Train the model\n        model.fit(X_train, y_train)\n        \n        # Validate the model\n        y_val_pred = model.predict(X_val)\n        score = accuracy_score(y_val, y_val_pred)\n        print(score)\n        \n        # Update the best model if the current one is better\n        if score > best_score:\n            best_score = score\n            best_params = params\n            best_model = model\n    \n    return best_params, best_model, best_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T01:34:28.197644Z","iopub.execute_input":"2024-11-22T01:34:28.198033Z","iopub.status.idle":"2024-11-22T01:34:28.209915Z","shell.execute_reply.started":"2024-11-22T01:34:28.197996Z","shell.execute_reply":"2024-11-22T01:34:28.208599Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"param_grid = {\n    'n_estimators': [80, 150, 200],\n    'learning_rate': [0.01, 0.1, 1.0],\n    'max_depth': [1, 2, 3]\n}\n\n# Perform grid search\nprint(\"Performing Grid Search...\")\nbest_params, best_model, best_score = grid_search(X_train, y_train, X_val, y_val, param_grid)\n\nprint(f\"Best Parameters: {best_params}\")\nprint(f\"Validation Accuracy: {best_score:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T01:34:28.211677Z","iopub.execute_input":"2024-11-22T01:34:28.212535Z","iopub.status.idle":"2024-11-22T03:57:07.207739Z","shell.execute_reply.started":"2024-11-22T01:34:28.212488Z","shell.execute_reply":"2024-11-22T03:57:07.204026Z"}},"outputs":[{"name":"stdout","text":"Performing Grid Search...\n{'n_estimators': 80, 'learning_rate': 0.01, 'max_depth': 1}\n0.7625\n{'n_estimators': 80, 'learning_rate': 0.01, 'max_depth': 2}\n0.8325\n{'n_estimators': 80, 'learning_rate': 0.01, 'max_depth': 3}\n0.855\n{'n_estimators': 80, 'learning_rate': 0.1, 'max_depth': 1}\n0.9025\n{'n_estimators': 80, 'learning_rate': 0.1, 'max_depth': 2}\n0.935\n{'n_estimators': 80, 'learning_rate': 0.1, 'max_depth': 3}\n0.905\n{'n_estimators': 80, 'learning_rate': 1.0, 'max_depth': 1}\n0.855\n{'n_estimators': 80, 'learning_rate': 1.0, 'max_depth': 2}\n0.875\n{'n_estimators': 80, 'learning_rate': 1.0, 'max_depth': 3}\n0.9475\n{'n_estimators': 150, 'learning_rate': 0.01, 'max_depth': 1}\n0.7875\n{'n_estimators': 150, 'learning_rate': 0.01, 'max_depth': 2}\n0.8675\n{'n_estimators': 150, 'learning_rate': 0.01, 'max_depth': 3}\n0.8875\n{'n_estimators': 150, 'learning_rate': 0.1, 'max_depth': 1}\n0.9225\n{'n_estimators': 150, 'learning_rate': 0.1, 'max_depth': 2}\n0.95\n{'n_estimators': 150, 'learning_rate': 0.1, 'max_depth': 3}\n0.925\n{'n_estimators': 150, 'learning_rate': 1.0, 'max_depth': 1}\n0.8675\n{'n_estimators': 150, 'learning_rate': 1.0, 'max_depth': 2}\n0.91\n{'n_estimators': 150, 'learning_rate': 1.0, 'max_depth': 3}\n0.9575\n{'n_estimators': 200, 'learning_rate': 0.01, 'max_depth': 1}\n0.7975\n{'n_estimators': 200, 'learning_rate': 0.01, 'max_depth': 2}\n0.88\n{'n_estimators': 200, 'learning_rate': 0.01, 'max_depth': 3}\n0.9\n{'n_estimators': 200, 'learning_rate': 0.1, 'max_depth': 1}\n0.9375\n{'n_estimators': 200, 'learning_rate': 0.1, 'max_depth': 2}\n0.9425\n{'n_estimators': 200, 'learning_rate': 0.1, 'max_depth': 3}\n0.9325\n{'n_estimators': 200, 'learning_rate': 1.0, 'max_depth': 1}\n0.875\n{'n_estimators': 200, 'learning_rate': 1.0, 'max_depth': 2}\n0.9425\n{'n_estimators': 200, 'learning_rate': 1.0, 'max_depth': 3}\n0.9675\nBest Parameters: {'n_estimators': 200, 'learning_rate': 1.0, 'max_depth': 3}\nValidation Accuracy: 0.9675\n","output_type":"stream"}],"execution_count":10}]}