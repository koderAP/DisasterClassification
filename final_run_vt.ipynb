{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7016d56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T07:30:27.385250Z",
     "iopub.status.busy": "2024-11-24T07:30:27.384884Z",
     "iopub.status.idle": "2024-11-24T09:45:48.543091Z",
     "shell.execute_reply": "2024-11-24T09:45:48.542040Z"
    },
    "papermill": {
     "duration": 8121.163317,
     "end_time": "2024-11-24T09:45:48.545068",
     "exception": false,
     "start_time": "2024-11-24T07:30:27.381751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\r\n",
      "100%|███████████████████████████████████████| 97.8M/97.8M [00:00<00:00, 197MB/s]\r\n",
      "Using Neural Network Model\r\n",
      "Training vit_base_patch16_224 model\r\n",
      "model.safetensors: 100%|██████████████████████| 346M/346M [00:01<00:00, 231MB/s]\r\n",
      "cuda\r\n",
      "Total parameters: 85,801,732\r\n",
      "Training vit_base_patch16_224 Epoch 1/10: 100%|█| 50/50 [01:09<00:00,  1.39s/it,\r\n",
      "Validating vit_base_patch16_224 Epoch 1/10: 100%|█| 13/13 [00:09<00:00,  1.30it/\r\n",
      "vit_base_patch16_224 Epoch 1/10, Train Loss: 0.2202, Train Acc: 91.69%, Val Loss: 0.1148, Val Acc: 96.75%\r\n",
      "Best model for vit_base_patch16_224 saved with Val Acc: 96.75%\r\n",
      "Training vit_base_patch16_224 Epoch 2/10: 100%|█| 50/50 [01:09<00:00,  1.38s/it,\r\n",
      "Validating vit_base_patch16_224 Epoch 2/10: 100%|█| 13/13 [00:09<00:00,  1.33it/\r\n",
      "vit_base_patch16_224 Epoch 2/10, Train Loss: 0.0305, Train Acc: 98.94%, Val Loss: 0.0709, Val Acc: 98.00%\r\n",
      "Best model for vit_base_patch16_224 saved with Val Acc: 98.00%\r\n",
      "Training vit_base_patch16_224 Epoch 3/10: 100%|█| 50/50 [01:09<00:00,  1.39s/it,\r\n",
      "Validating vit_base_patch16_224 Epoch 3/10: 100%|█| 13/13 [00:09<00:00,  1.31it/\r\n",
      "vit_base_patch16_224 Epoch 3/10, Train Loss: 0.0193, Train Acc: 99.12%, Val Loss: 0.1849, Val Acc: 95.50%\r\n",
      "Training vit_base_patch16_224 Epoch 4/10: 100%|█| 50/50 [01:09<00:00,  1.38s/it,\r\n",
      "Validating vit_base_patch16_224 Epoch 4/10: 100%|█| 13/13 [00:09<00:00,  1.34it/\r\n",
      "vit_base_patch16_224 Epoch 4/10, Train Loss: 0.0582, Train Acc: 98.12%, Val Loss: 0.1725, Val Acc: 94.00%\r\n",
      "Training vit_base_patch16_224 Epoch 5/10: 100%|█| 50/50 [01:09<00:00,  1.38s/it,\r\n",
      "Validating vit_base_patch16_224 Epoch 5/10: 100%|█| 13/13 [00:10<00:00,  1.27it/\r\n",
      "vit_base_patch16_224 Epoch 5/10, Train Loss: 0.0164, Train Acc: 99.44%, Val Loss: 0.1403, Val Acc: 96.75%\r\n",
      "Training vit_base_patch16_224 Epoch 6/10: 100%|█| 50/50 [01:09<00:00,  1.38s/it,\r\n",
      "Validating vit_base_patch16_224 Epoch 6/10: 100%|█| 13/13 [00:09<00:00,  1.33it/\r\n",
      "vit_base_patch16_224 Epoch 6/10, Train Loss: 0.0449, Train Acc: 98.62%, Val Loss: 0.1693, Val Acc: 97.00%\r\n",
      "Training vit_base_patch16_224 Epoch 7/10: 100%|█| 50/50 [01:08<00:00,  1.38s/it,\r\n",
      "Validating vit_base_patch16_224 Epoch 7/10: 100%|█| 13/13 [00:09<00:00,  1.32it/\r\n",
      "vit_base_patch16_224 Epoch 7/10, Train Loss: 0.0205, Train Acc: 99.31%, Val Loss: 0.1002, Val Acc: 98.00%\r\n",
      "Training vit_base_patch16_224 Epoch 8/10: 100%|█| 50/50 [01:08<00:00,  1.38s/it,\r\n",
      "Validating vit_base_patch16_224 Epoch 8/10: 100%|█| 13/13 [00:09<00:00,  1.32it/\r\n",
      "vit_base_patch16_224 Epoch 8/10, Train Loss: 0.0260, Train Acc: 99.25%, Val Loss: 0.3692, Val Acc: 92.00%\r\n",
      "Training vit_base_patch16_224 Epoch 9/10: 100%|█| 50/50 [01:09<00:00,  1.38s/it,\r\n",
      "Validating vit_base_patch16_224 Epoch 9/10: 100%|█| 13/13 [00:09<00:00,  1.32it/\r\n",
      "vit_base_patch16_224 Epoch 9/10, Train Loss: 0.0248, Train Acc: 99.00%, Val Loss: 0.2019, Val Acc: 96.50%\r\n",
      "Training vit_base_patch16_224 Epoch 10/10: 100%|█| 50/50 [01:09<00:00,  1.39s/it\r\n",
      "Validating vit_base_patch16_224 Epoch 10/10: 100%|█| 13/13 [00:09<00:00,  1.34it\r\n",
      "vit_base_patch16_224 Epoch 10/10, Train Loss: 0.0244, Train Acc: 99.25%, Val Loss: 0.1312, Val Acc: 96.75%\r\n",
      "/kaggle/input/ml-ass/nn_models.py:215: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\r\n",
      "  model.load_state_dict(torch.load(f\"best_{model_name}_model.pth\"))\r\n",
      "Classification Report for train vit_base_patch16_224:\r\n",
      "               precision    recall  f1-score   support\r\n",
      "\r\n",
      "           0     1.0000    0.9950    0.9975       400\r\n",
      "           1     1.0000    0.9925    0.9962       400\r\n",
      "           2     0.9926    1.0000    0.9963       400\r\n",
      "           3     0.9950    1.0000    0.9975       400\r\n",
      "\r\n",
      "    accuracy                         0.9969      1600\r\n",
      "   macro avg     0.9969    0.9969    0.9969      1600\r\n",
      "weighted avg     0.9969    0.9969    0.9969      1600\r\n",
      "\r\n",
      "Train F1 Score for vit_base_patch16_224: 0.9969\r\n",
      "Classification Report for valvit_base_patch16_224:\r\n",
      "               precision    recall  f1-score   support\r\n",
      "\r\n",
      "           0     0.9899    0.9800    0.9849       100\r\n",
      "           1     0.9899    0.9800    0.9849       100\r\n",
      "           2     0.9703    0.9800    0.9751       100\r\n",
      "           3     0.9703    0.9800    0.9751       100\r\n",
      "\r\n",
      "    accuracy                         0.9800       400\r\n",
      "   macro avg     0.9801    0.9800    0.9800       400\r\n",
      "weighted avg     0.9801    0.9800    0.9800       400\r\n",
      "\r\n",
      "Training custom_cnn model\r\n",
      "cuda\r\n",
      "Total parameters: 19,775,748\r\n",
      "Training custom_cnn Epoch 1/20: 100%|█| 50/50 [00:41<00:00,  1.20it/s, accuracy=\r\n",
      "Validating custom_cnn Epoch 1/20: 100%|█| 13/13 [00:07<00:00,  1.70it/s, accurac\r\n",
      "custom_cnn Epoch 1/20, Train Loss: 1.1502, Train Acc: 52.06%, Val Loss: 0.6230, Val Acc: 80.75%\r\n",
      "Best model for custom_cnn saved with Val Acc: 80.75%\r\n",
      "Training custom_cnn Epoch 2/20: 100%|█| 50/50 [00:41<00:00,  1.20it/s, accuracy=\r\n",
      "Validating custom_cnn Epoch 2/20: 100%|█| 13/13 [00:07<00:00,  1.79it/s, accurac\r\n",
      "custom_cnn Epoch 2/20, Train Loss: 0.6861, Train Acc: 74.06%, Val Loss: 0.4758, Val Acc: 83.00%\r\n",
      "Best model for custom_cnn saved with Val Acc: 83.00%\r\n",
      "Training custom_cnn Epoch 3/20: 100%|█| 50/50 [00:41<00:00,  1.21it/s, accuracy=\r\n",
      "Validating custom_cnn Epoch 3/20: 100%|█| 13/13 [00:07<00:00,  1.68it/s, accurac\r\n",
      "custom_cnn Epoch 3/20, Train Loss: 0.5674, Train Acc: 80.06%, Val Loss: 0.4379, Val Acc: 84.75%\r\n",
      "Best model for custom_cnn saved with Val Acc: 84.75%\r\n",
      "Training custom_cnn Epoch 4/20: 100%|█| 50/50 [00:41<00:00,  1.21it/s, accuracy=\r\n",
      "Validating custom_cnn Epoch 4/20: 100%|█| 13/13 [00:07<00:00,  1.74it/s, accurac\r\n",
      "custom_cnn Epoch 4/20, Train Loss: 0.5073, Train Acc: 81.12%, Val Loss: 0.4098, Val Acc: 86.25%\r\n",
      "Best model for custom_cnn saved with Val Acc: 86.25%\r\n",
      "Training custom_cnn Epoch 5/20: 100%|█| 50/50 [00:41<00:00,  1.21it/s, accuracy=\r\n",
      "Validating custom_cnn Epoch 5/20: 100%|█| 13/13 [00:07<00:00,  1.75it/s, accurac\r\n",
      "custom_cnn Epoch 5/20, Train Loss: 0.4320, Train Acc: 84.50%, Val Loss: 0.5320, Val Acc: 79.50%\r\n",
      "Training custom_cnn Epoch 6/20: 100%|█| 50/50 [00:41<00:00,  1.20it/s, accuracy=\r\n",
      "Validating custom_cnn Epoch 6/20: 100%|█| 13/13 [00:07<00:00,  1.77it/s, accurac\r\n",
      "custom_cnn Epoch 6/20, Train Loss: 0.4137, Train Acc: 85.81%, Val Loss: 0.3569, Val Acc: 87.50%\r\n",
      "Best model for custom_cnn saved with Val Acc: 87.50%\r\n",
      "Training custom_cnn Epoch 7/20: 100%|█| 50/50 [00:41<00:00,  1.19it/s, accuracy=\r\n",
      "Validating custom_cnn Epoch 7/20: 100%|█| 13/13 [00:07<00:00,  1.75it/s, accurac\r\n",
      "custom_cnn Epoch 7/20, Train Loss: 0.3592, Train Acc: 87.94%, Val Loss: 0.3869, Val Acc: 84.75%\r\n",
      "Training custom_cnn Epoch 8/20: 100%|█| 50/50 [00:41<00:00,  1.21it/s, accuracy=\r\n",
      "Validating custom_cnn Epoch 8/20: 100%|█| 13/13 [00:07<00:00,  1.76it/s, accurac\r\n",
      "custom_cnn Epoch 8/20, Train Loss: 0.3929, Train Acc: 86.38%, Val Loss: 0.4101, Val Acc: 87.00%\r\n",
      "Training custom_cnn Epoch 9/20: 100%|█| 50/50 [00:41<00:00,  1.20it/s, accuracy=\r\n",
      "Validating custom_cnn Epoch 9/20: 100%|█| 13/13 [00:07<00:00,  1.73it/s, accurac\r\n",
      "custom_cnn Epoch 9/20, Train Loss: 0.3269, Train Acc: 90.19%, Val Loss: 0.3730, Val Acc: 86.50%\r\n",
      "Training custom_cnn Epoch 10/20: 100%|█| 50/50 [00:41<00:00,  1.21it/s, accuracy\r\n",
      "Validating custom_cnn Epoch 10/20: 100%|█| 13/13 [00:07<00:00,  1.75it/s, accura\r\n",
      "custom_cnn Epoch 10/20, Train Loss: 0.3090, Train Acc: 90.19%, Val Loss: 0.3807, Val Acc: 86.50%\r\n",
      "Training custom_cnn Epoch 11/20: 100%|█| 50/50 [00:42<00:00,  1.19it/s, accuracy\r\n",
      "Validating custom_cnn Epoch 11/20: 100%|█| 13/13 [00:07<00:00,  1.78it/s, accura\r\n",
      "custom_cnn Epoch 11/20, Train Loss: 0.3217, Train Acc: 89.44%, Val Loss: 0.3504, Val Acc: 87.50%\r\n",
      "Training custom_cnn Epoch 12/20: 100%|█| 50/50 [00:41<00:00,  1.21it/s, accuracy\r\n",
      "Validating custom_cnn Epoch 12/20: 100%|█| 13/13 [00:07<00:00,  1.67it/s, accura\r\n",
      "custom_cnn Epoch 12/20, Train Loss: 0.3059, Train Acc: 90.19%, Val Loss: 0.3041, Val Acc: 88.25%\r\n",
      "Best model for custom_cnn saved with Val Acc: 88.25%\r\n",
      "Training custom_cnn Epoch 13/20: 100%|█| 50/50 [00:41<00:00,  1.20it/s, accuracy\r\n",
      "Validating custom_cnn Epoch 13/20: 100%|█| 13/13 [00:07<00:00,  1.77it/s, accura\r\n",
      "custom_cnn Epoch 13/20, Train Loss: 0.2631, Train Acc: 90.88%, Val Loss: 0.4771, Val Acc: 86.00%\r\n",
      "Training custom_cnn Epoch 14/20: 100%|█| 50/50 [00:41<00:00,  1.20it/s, accuracy\r\n",
      "Validating custom_cnn Epoch 14/20: 100%|█| 13/13 [00:07<00:00,  1.70it/s, accura\r\n",
      "custom_cnn Epoch 14/20, Train Loss: 0.2838, Train Acc: 90.81%, Val Loss: 0.3870, Val Acc: 87.00%\r\n",
      "Training custom_cnn Epoch 15/20: 100%|█| 50/50 [00:41<00:00,  1.20it/s, accuracy\r\n",
      "Validating custom_cnn Epoch 15/20: 100%|█| 13/13 [00:07<00:00,  1.75it/s, accura\r\n",
      "custom_cnn Epoch 15/20, Train Loss: 0.2491, Train Acc: 92.12%, Val Loss: 0.3748, Val Acc: 87.25%\r\n",
      "Training custom_cnn Epoch 16/20: 100%|█| 50/50 [00:41<00:00,  1.20it/s, accuracy\r\n",
      "Validating custom_cnn Epoch 16/20: 100%|█| 13/13 [00:07<00:00,  1.78it/s, accura\r\n",
      "custom_cnn Epoch 16/20, Train Loss: 0.2240, Train Acc: 92.88%, Val Loss: 0.3769, Val Acc: 87.25%\r\n",
      "Training custom_cnn Epoch 17/20: 100%|█| 50/50 [00:41<00:00,  1.19it/s, accuracy\r\n",
      "Validating custom_cnn Epoch 17/20: 100%|█| 13/13 [00:07<00:00,  1.74it/s, accura\r\n",
      "custom_cnn Epoch 17/20, Train Loss: 0.2271, Train Acc: 92.50%, Val Loss: 0.3424, Val Acc: 86.25%\r\n",
      "Training custom_cnn Epoch 18/20: 100%|█| 50/50 [00:41<00:00,  1.20it/s, accuracy\r\n",
      "Validating custom_cnn Epoch 18/20: 100%|█| 13/13 [00:07<00:00,  1.76it/s, accura\r\n",
      "custom_cnn Epoch 18/20, Train Loss: 0.2583, Train Acc: 90.94%, Val Loss: 0.5121, Val Acc: 83.25%\r\n",
      "Training custom_cnn Epoch 19/20: 100%|█| 50/50 [00:41<00:00,  1.19it/s, accuracy\r\n",
      "Validating custom_cnn Epoch 19/20: 100%|█| 13/13 [00:07<00:00,  1.75it/s, accura\r\n",
      "custom_cnn Epoch 19/20, Train Loss: 0.2410, Train Acc: 92.44%, Val Loss: 0.2972, Val Acc: 88.50%\r\n",
      "Best model for custom_cnn saved with Val Acc: 88.50%\r\n",
      "Training custom_cnn Epoch 20/20: 100%|█| 50/50 [00:41<00:00,  1.19it/s, accuracy\r\n",
      "Validating custom_cnn Epoch 20/20: 100%|█| 13/13 [00:07<00:00,  1.74it/s, accura\r\n",
      "custom_cnn Epoch 20/20, Train Loss: 0.1960, Train Acc: 93.56%, Val Loss: 0.3583, Val Acc: 87.50%\r\n",
      "/kaggle/input/ml-ass/nn_models.py:215: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\r\n",
      "  model.load_state_dict(torch.load(f\"best_{model_name}_model.pth\"))\r\n",
      "Classification Report for train custom_cnn:\r\n",
      "               precision    recall  f1-score   support\r\n",
      "\r\n",
      "           0     0.9749    0.9725    0.9737       400\r\n",
      "           1     0.8821    0.9725    0.9251       400\r\n",
      "           2     0.9854    0.8425    0.9084       400\r\n",
      "           3     0.9450    0.9875    0.9658       400\r\n",
      "\r\n",
      "    accuracy                         0.9437      1600\r\n",
      "   macro avg     0.9468    0.9438    0.9432      1600\r\n",
      "weighted avg     0.9468    0.9437    0.9432      1600\r\n",
      "\r\n",
      "Train F1 Score for custom_cnn: 0.9432\r\n",
      "Classification Report for valcustom_cnn:\r\n",
      "               precision    recall  f1-score   support\r\n",
      "\r\n",
      "           0     0.9278    0.9000    0.9137       100\r\n",
      "           1     0.8598    0.9200    0.8889       100\r\n",
      "           2     0.9634    0.7900    0.8681       100\r\n",
      "           3     0.8158    0.9300    0.8692       100\r\n",
      "\r\n",
      "    accuracy                         0.8850       400\r\n",
      "   macro avg     0.8917    0.8850    0.8850       400\r\n",
      "weighted avg     0.8917    0.8850    0.8850       400\r\n",
      "\r\n",
      "Training resnet50 model\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "cuda\r\n",
      "Total parameters: 24,559,172\r\n",
      "Training resnet50 Epoch 1/10: 100%|█| 50/50 [00:46<00:00,  1.09it/s, accuracy=92\r\n",
      "Validating resnet50 Epoch 1/10: 100%|█| 13/13 [00:07<00:00,  1.64it/s, accuracy=\r\n",
      "resnet50 Epoch 1/10, Train Loss: 0.2952, Train Acc: 92.25%, Val Loss: 0.1030, Val Acc: 96.25%\r\n",
      "Best model for resnet50 saved with Val Acc: 96.25%\r\n",
      "Training resnet50 Epoch 2/10: 100%|█| 50/50 [00:46<00:00,  1.07it/s, accuracy=98\r\n",
      "Validating resnet50 Epoch 2/10: 100%|█| 13/13 [00:07<00:00,  1.67it/s, accuracy=\r\n",
      "resnet50 Epoch 2/10, Train Loss: 0.0631, Train Acc: 98.06%, Val Loss: 0.1569, Val Acc: 96.50%\r\n",
      "Best model for resnet50 saved with Val Acc: 96.50%\r\n",
      "Training resnet50 Epoch 3/10: 100%|█| 50/50 [00:46<00:00,  1.08it/s, accuracy=99\r\n",
      "Validating resnet50 Epoch 3/10: 100%|█| 13/13 [00:07<00:00,  1.69it/s, accuracy=\r\n",
      "resnet50 Epoch 3/10, Train Loss: 0.0201, Train Acc: 99.69%, Val Loss: 0.0790, Val Acc: 97.25%\r\n",
      "Best model for resnet50 saved with Val Acc: 97.25%\r\n",
      "Training resnet50 Epoch 4/10: 100%|█| 50/50 [00:45<00:00,  1.10it/s, accuracy=99\r\n",
      "Validating resnet50 Epoch 4/10: 100%|█| 13/13 [00:07<00:00,  1.63it/s, accuracy=\r\n",
      "resnet50 Epoch 4/10, Train Loss: 0.0327, Train Acc: 99.00%, Val Loss: 0.0952, Val Acc: 97.25%\r\n",
      "Training resnet50 Epoch 5/10: 100%|█| 50/50 [00:45<00:00,  1.09it/s, accuracy=98\r\n",
      "Validating resnet50 Epoch 5/10: 100%|█| 13/13 [00:07<00:00,  1.69it/s, accuracy=\r\n",
      "resnet50 Epoch 5/10, Train Loss: 0.0504, Train Acc: 98.81%, Val Loss: 0.0845, Val Acc: 97.00%\r\n",
      "Training resnet50 Epoch 6/10: 100%|█| 50/50 [00:46<00:00,  1.08it/s, accuracy=99\r\n",
      "Validating resnet50 Epoch 6/10: 100%|█| 13/13 [00:07<00:00,  1.66it/s, accuracy=\r\n",
      "resnet50 Epoch 6/10, Train Loss: 0.0138, Train Acc: 99.69%, Val Loss: 0.1068, Val Acc: 96.75%\r\n",
      "Training resnet50 Epoch 7/10: 100%|█| 50/50 [00:45<00:00,  1.09it/s, accuracy=99\r\n",
      "Validating resnet50 Epoch 7/10: 100%|█| 13/13 [00:07<00:00,  1.63it/s, accuracy=\r\n",
      "resnet50 Epoch 7/10, Train Loss: 0.0075, Train Acc: 99.81%, Val Loss: 0.1049, Val Acc: 97.00%\r\n",
      "Training resnet50 Epoch 8/10: 100%|█| 50/50 [00:45<00:00,  1.10it/s, accuracy=99\r\n",
      "Validating resnet50 Epoch 8/10: 100%|█| 13/13 [00:07<00:00,  1.69it/s, accuracy=\r\n",
      "resnet50 Epoch 8/10, Train Loss: 0.0251, Train Acc: 99.25%, Val Loss: 0.3421, Val Acc: 92.75%\r\n",
      "Training resnet50 Epoch 9/10: 100%|█| 50/50 [00:45<00:00,  1.09it/s, accuracy=99\r\n",
      "Validating resnet50 Epoch 9/10: 100%|█| 13/13 [00:07<00:00,  1.67it/s, accuracy=\r\n",
      "resnet50 Epoch 9/10, Train Loss: 0.0284, Train Acc: 99.25%, Val Loss: 0.1458, Val Acc: 95.75%\r\n",
      "Training resnet50 Epoch 10/10: 100%|█| 50/50 [00:45<00:00,  1.09it/s, accuracy=9\r\n",
      "Validating resnet50 Epoch 10/10: 100%|█| 13/13 [00:08<00:00,  1.59it/s, accuracy\r\n",
      "resnet50 Epoch 10/10, Train Loss: 0.0332, Train Acc: 98.81%, Val Loss: 0.1417, Val Acc: 95.75%\r\n",
      "/kaggle/input/ml-ass/nn_models.py:215: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\r\n",
      "  model.load_state_dict(torch.load(f\"best_{model_name}_model.pth\"))\r\n",
      "Classification Report for train resnet50:\r\n",
      "               precision    recall  f1-score   support\r\n",
      "\r\n",
      "           0     1.0000    1.0000    1.0000       400\r\n",
      "           1     1.0000    1.0000    1.0000       400\r\n",
      "           2     1.0000    1.0000    1.0000       400\r\n",
      "           3     1.0000    1.0000    1.0000       400\r\n",
      "\r\n",
      "    accuracy                         1.0000      1600\r\n",
      "   macro avg     1.0000    1.0000    1.0000      1600\r\n",
      "weighted avg     1.0000    1.0000    1.0000      1600\r\n",
      "\r\n",
      "Train F1 Score for resnet50: 1.0000\r\n",
      "Classification Report for valresnet50:\r\n",
      "               precision    recall  f1-score   support\r\n",
      "\r\n",
      "           0     0.9615    1.0000    0.9804       100\r\n",
      "           1     0.9612    0.9900    0.9754       100\r\n",
      "           2     1.0000    0.9300    0.9637       100\r\n",
      "           3     0.9700    0.9700    0.9700       100\r\n",
      "\r\n",
      "    accuracy                         0.9725       400\r\n",
      "   macro avg     0.9732    0.9725    0.9724       400\r\n",
      "weighted avg     0.9732    0.9725    0.9724       400\r\n",
      "\r\n",
      "Training densenet121 model\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\r\n",
      "100%|██████████████████████████████████████| 30.8M/30.8M [00:00<00:00, 87.2MB/s]\r\n",
      "cuda\r\n",
      "Total parameters: 7,480,708\r\n",
      "Training densenet121 Epoch 1/10: 100%|█| 50/50 [00:47<00:00,  1.06it/s, accuracy\r\n",
      "Validating densenet121 Epoch 1/10: 100%|█| 13/13 [00:08<00:00,  1.62it/s, accura\r\n",
      "densenet121 Epoch 1/10, Train Loss: 0.5141, Train Acc: 86.06%, Val Loss: 0.1183, Val Acc: 97.25%\r\n",
      "Best model for densenet121 saved with Val Acc: 97.25%\r\n",
      "Training densenet121 Epoch 2/10: 100%|█| 50/50 [00:46<00:00,  1.07it/s, accuracy\r\n",
      "Validating densenet121 Epoch 2/10: 100%|█| 13/13 [00:08<00:00,  1.59it/s, accura\r\n",
      "densenet121 Epoch 2/10, Train Loss: 0.0899, Train Acc: 97.56%, Val Loss: 0.0864, Val Acc: 97.75%\r\n",
      "Best model for densenet121 saved with Val Acc: 97.75%\r\n",
      "Training densenet121 Epoch 3/10: 100%|█| 50/50 [00:46<00:00,  1.08it/s, accuracy\r\n",
      "Validating densenet121 Epoch 3/10: 100%|█| 13/13 [00:07<00:00,  1.66it/s, accura\r\n",
      "densenet121 Epoch 3/10, Train Loss: 0.0250, Train Acc: 99.44%, Val Loss: 0.0739, Val Acc: 97.50%\r\n",
      "Training densenet121 Epoch 4/10: 100%|█| 50/50 [00:46<00:00,  1.07it/s, accuracy\r\n",
      "Validating densenet121 Epoch 4/10: 100%|█| 13/13 [00:08<00:00,  1.60it/s, accura\r\n",
      "densenet121 Epoch 4/10, Train Loss: 0.0216, Train Acc: 99.56%, Val Loss: 0.0603, Val Acc: 98.50%\r\n",
      "Best model for densenet121 saved with Val Acc: 98.50%\r\n",
      "Training densenet121 Epoch 5/10: 100%|█| 50/50 [00:46<00:00,  1.07it/s, accuracy\r\n",
      "Validating densenet121 Epoch 5/10: 100%|█| 13/13 [00:07<00:00,  1.67it/s, accura\r\n",
      "densenet121 Epoch 5/10, Train Loss: 0.0108, Train Acc: 99.81%, Val Loss: 0.0657, Val Acc: 98.00%\r\n",
      "Training densenet121 Epoch 6/10: 100%|█| 50/50 [00:47<00:00,  1.06it/s, accuracy\r\n",
      "Validating densenet121 Epoch 6/10: 100%|█| 13/13 [00:08<00:00,  1.57it/s, accura\r\n",
      "densenet121 Epoch 6/10, Train Loss: 0.0186, Train Acc: 99.62%, Val Loss: 0.1091, Val Acc: 97.00%\r\n",
      "Training densenet121 Epoch 7/10: 100%|█| 50/50 [00:46<00:00,  1.07it/s, accuracy\r\n",
      "Validating densenet121 Epoch 7/10: 100%|█| 13/13 [00:07<00:00,  1.64it/s, accura\r\n",
      "densenet121 Epoch 7/10, Train Loss: 0.0175, Train Acc: 99.44%, Val Loss: 0.0670, Val Acc: 98.00%\r\n",
      "Training densenet121 Epoch 8/10: 100%|█| 50/50 [00:46<00:00,  1.07it/s, accuracy\r\n",
      "Validating densenet121 Epoch 8/10: 100%|█| 13/13 [00:07<00:00,  1.64it/s, accura\r\n",
      "densenet121 Epoch 8/10, Train Loss: 0.0073, Train Acc: 99.94%, Val Loss: 0.0886, Val Acc: 97.75%\r\n",
      "Training densenet121 Epoch 9/10: 100%|█| 50/50 [00:46<00:00,  1.08it/s, accuracy\r\n",
      "Validating densenet121 Epoch 9/10: 100%|█| 13/13 [00:08<00:00,  1.52it/s, accura\r\n",
      "densenet121 Epoch 9/10, Train Loss: 0.0036, Train Acc: 100.00%, Val Loss: 0.0754, Val Acc: 97.75%\r\n",
      "Training densenet121 Epoch 10/10: 100%|█| 50/50 [00:46<00:00,  1.07it/s, accurac\r\n",
      "Validating densenet121 Epoch 10/10: 100%|█| 13/13 [00:08<00:00,  1.62it/s, accur\r\n",
      "densenet121 Epoch 10/10, Train Loss: 0.0068, Train Acc: 99.75%, Val Loss: 0.0898, Val Acc: 97.25%\r\n",
      "/kaggle/input/ml-ass/nn_models.py:215: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\r\n",
      "  model.load_state_dict(torch.load(f\"best_{model_name}_model.pth\"))\r\n",
      "Classification Report for train densenet121:\r\n",
      "               precision    recall  f1-score   support\r\n",
      "\r\n",
      "           0     1.0000    1.0000    1.0000       400\r\n",
      "           1     1.0000    1.0000    1.0000       400\r\n",
      "           2     1.0000    1.0000    1.0000       400\r\n",
      "           3     1.0000    1.0000    1.0000       400\r\n",
      "\r\n",
      "    accuracy                         1.0000      1600\r\n",
      "   macro avg     1.0000    1.0000    1.0000      1600\r\n",
      "weighted avg     1.0000    1.0000    1.0000      1600\r\n",
      "\r\n",
      "Train F1 Score for densenet121: 1.0000\r\n",
      "Classification Report for valdensenet121:\r\n",
      "               precision    recall  f1-score   support\r\n",
      "\r\n",
      "           0     0.9706    0.9900    0.9802       100\r\n",
      "           1     0.9901    1.0000    0.9950       100\r\n",
      "           2     0.9802    0.9900    0.9851       100\r\n",
      "           3     1.0000    0.9600    0.9796       100\r\n",
      "\r\n",
      "    accuracy                         0.9850       400\r\n",
      "   macro avg     0.9852    0.9850    0.9850       400\r\n",
      "weighted avg     0.9852    0.9850    0.9850       400\r\n",
      "\r\n",
      "Training vgg16 model\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\r\n",
      "100%|█████████████████████████████████████████| 528M/528M [00:02<00:00, 204MB/s]\r\n",
      "cuda\r\n",
      "Total parameters: 136,360,260\r\n",
      "Training vgg16 Epoch 1/10: 100%|█| 50/50 [00:51<00:00,  1.02s/it, accuracy=86.9,\r\n",
      "Validating vgg16 Epoch 1/10: 100%|█| 13/13 [00:08<00:00,  1.60it/s, accuracy=95.\r\n",
      "vgg16 Epoch 1/10, Train Loss: 0.3284, Train Acc: 86.94%, Val Loss: 0.1357, Val Acc: 95.50%\r\n",
      "Best model for vgg16 saved with Val Acc: 95.50%\r\n",
      "Training vgg16 Epoch 2/10: 100%|█| 50/50 [00:50<00:00,  1.01s/it, accuracy=96.4,\r\n",
      "Validating vgg16 Epoch 2/10: 100%|█| 13/13 [00:08<00:00,  1.60it/s, accuracy=95.\r\n",
      "vgg16 Epoch 2/10, Train Loss: 0.0964, Train Acc: 96.44%, Val Loss: 0.1338, Val Acc: 95.50%\r\n",
      "Training vgg16 Epoch 3/10: 100%|█| 50/50 [00:50<00:00,  1.01s/it, accuracy=97.9,\r\n",
      "Validating vgg16 Epoch 3/10: 100%|█| 13/13 [00:08<00:00,  1.57it/s, accuracy=97,\r\n",
      "vgg16 Epoch 3/10, Train Loss: 0.0578, Train Acc: 97.94%, Val Loss: 0.0964, Val Acc: 97.00%\r\n",
      "Best model for vgg16 saved with Val Acc: 97.00%\r\n",
      "Training vgg16 Epoch 4/10: 100%|█| 50/50 [00:50<00:00,  1.02s/it, accuracy=99.1,\r\n",
      "Validating vgg16 Epoch 4/10: 100%|█| 13/13 [00:08<00:00,  1.56it/s, accuracy=98.\r\n",
      "vgg16 Epoch 4/10, Train Loss: 0.0287, Train Acc: 99.06%, Val Loss: 0.0816, Val Acc: 98.25%\r\n",
      "Best model for vgg16 saved with Val Acc: 98.25%\r\n",
      "Training vgg16 Epoch 5/10: 100%|█| 50/50 [00:50<00:00,  1.01s/it, accuracy=99.4,\r\n",
      "Validating vgg16 Epoch 5/10: 100%|█| 13/13 [00:08<00:00,  1.61it/s, accuracy=97.\r\n",
      "vgg16 Epoch 5/10, Train Loss: 0.0120, Train Acc: 99.38%, Val Loss: 0.0623, Val Acc: 97.50%\r\n",
      "Training vgg16 Epoch 6/10: 100%|█| 50/50 [00:50<00:00,  1.01s/it, accuracy=98.4,\r\n",
      "Validating vgg16 Epoch 6/10: 100%|█| 13/13 [00:08<00:00,  1.59it/s, accuracy=95.\r\n",
      "vgg16 Epoch 6/10, Train Loss: 0.0695, Train Acc: 98.38%, Val Loss: 0.1605, Val Acc: 95.25%\r\n",
      "Training vgg16 Epoch 7/10: 100%|█| 50/50 [00:50<00:00,  1.01s/it, accuracy=95.9,\r\n",
      "Validating vgg16 Epoch 7/10: 100%|█| 13/13 [00:08<00:00,  1.59it/s, accuracy=93,\r\n",
      "vgg16 Epoch 7/10, Train Loss: 0.1265, Train Acc: 95.94%, Val Loss: 0.2967, Val Acc: 93.00%\r\n",
      "Training vgg16 Epoch 8/10: 100%|█| 50/50 [00:50<00:00,  1.01s/it, accuracy=99.1,\r\n",
      "Validating vgg16 Epoch 8/10: 100%|█| 13/13 [00:08<00:00,  1.59it/s, accuracy=96.\r\n",
      "vgg16 Epoch 8/10, Train Loss: 0.0335, Train Acc: 99.06%, Val Loss: 0.2108, Val Acc: 96.25%\r\n",
      "Training vgg16 Epoch 9/10: 100%|█| 50/50 [00:51<00:00,  1.02s/it, accuracy=98.2,\r\n",
      "Validating vgg16 Epoch 9/10: 100%|█| 13/13 [00:08<00:00,  1.57it/s, accuracy=96.\r\n",
      "vgg16 Epoch 9/10, Train Loss: 0.0819, Train Acc: 98.19%, Val Loss: 0.1382, Val Acc: 96.75%\r\n",
      "Training vgg16 Epoch 10/10: 100%|█| 50/50 [00:50<00:00,  1.01s/it, accuracy=98.2\r\n",
      "Validating vgg16 Epoch 10/10: 100%|█| 13/13 [00:08<00:00,  1.55it/s, accuracy=96\r\n",
      "vgg16 Epoch 10/10, Train Loss: 0.0684, Train Acc: 98.19%, Val Loss: 0.1483, Val Acc: 96.50%\r\n",
      "/kaggle/input/ml-ass/nn_models.py:215: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\r\n",
      "  model.load_state_dict(torch.load(f\"best_{model_name}_model.pth\"))\r\n",
      "Classification Report for train vgg16:\r\n",
      "               precision    recall  f1-score   support\r\n",
      "\r\n",
      "           0     1.0000    1.0000    1.0000       400\r\n",
      "           1     1.0000    1.0000    1.0000       400\r\n",
      "           2     1.0000    1.0000    1.0000       400\r\n",
      "           3     1.0000    1.0000    1.0000       400\r\n",
      "\r\n",
      "    accuracy                         1.0000      1600\r\n",
      "   macro avg     1.0000    1.0000    1.0000      1600\r\n",
      "weighted avg     1.0000    1.0000    1.0000      1600\r\n",
      "\r\n",
      "Train F1 Score for vgg16: 1.0000\r\n",
      "Classification Report for valvgg16:\r\n",
      "               precision    recall  f1-score   support\r\n",
      "\r\n",
      "           0     0.9804    1.0000    0.9901       100\r\n",
      "           1     0.9709    1.0000    0.9852       100\r\n",
      "           2     0.9802    0.9900    0.9851       100\r\n",
      "           3     1.0000    0.9400    0.9691       100\r\n",
      "\r\n",
      "    accuracy                         0.9825       400\r\n",
      "   macro avg     0.9829    0.9825    0.9824       400\r\n",
      "weighted avg     0.9829    0.9825    0.9824       400\r\n",
      "\r\n",
      "Training mobilenet_v2 model\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\r\n",
      "100%|██████████████████████████████████████| 13.6M/13.6M [00:00<00:00, 75.6MB/s]\r\n",
      "cuda\r\n",
      "Total parameters: 2,881,796\r\n",
      "Training mobilenet_v2 Epoch 1/10: 100%|█| 50/50 [00:40<00:00,  1.23it/s, accurac\r\n",
      "Validating mobilenet_v2 Epoch 1/10: 100%|█| 13/13 [00:07<00:00,  1.79it/s, accur\r\n",
      "mobilenet_v2 Epoch 1/10, Train Loss: 0.4226, Train Acc: 88.50%, Val Loss: 0.1102, Val Acc: 96.50%\r\n",
      "Best model for mobilenet_v2 saved with Val Acc: 96.50%\r\n",
      "Training mobilenet_v2 Epoch 2/10: 100%|█| 50/50 [00:40<00:00,  1.22it/s, accurac\r\n",
      "Validating mobilenet_v2 Epoch 2/10: 100%|█| 13/13 [00:07<00:00,  1.75it/s, accur\r\n",
      "mobilenet_v2 Epoch 2/10, Train Loss: 0.0783, Train Acc: 97.38%, Val Loss: 0.0713, Val Acc: 97.75%\r\n",
      "Best model for mobilenet_v2 saved with Val Acc: 97.75%\r\n",
      "Training mobilenet_v2 Epoch 3/10: 100%|█| 50/50 [00:41<00:00,  1.22it/s, accurac\r\n",
      "Validating mobilenet_v2 Epoch 3/10: 100%|█| 13/13 [00:07<00:00,  1.71it/s, accur\r\n",
      "mobilenet_v2 Epoch 3/10, Train Loss: 0.0338, Train Acc: 99.06%, Val Loss: 0.0762, Val Acc: 97.25%\r\n",
      "Training mobilenet_v2 Epoch 4/10: 100%|█| 50/50 [00:41<00:00,  1.22it/s, accurac\r\n",
      "Validating mobilenet_v2 Epoch 4/10: 100%|█| 13/13 [00:07<00:00,  1.78it/s, accur\r\n",
      "mobilenet_v2 Epoch 4/10, Train Loss: 0.0282, Train Acc: 99.00%, Val Loss: 0.0840, Val Acc: 97.50%\r\n",
      "Training mobilenet_v2 Epoch 5/10: 100%|█| 50/50 [00:41<00:00,  1.22it/s, accurac\r\n",
      "Validating mobilenet_v2 Epoch 5/10: 100%|█| 13/13 [00:07<00:00,  1.77it/s, accur\r\n",
      "mobilenet_v2 Epoch 5/10, Train Loss: 0.0231, Train Acc: 99.25%, Val Loss: 0.0637, Val Acc: 97.25%\r\n",
      "Training mobilenet_v2 Epoch 6/10: 100%|█| 50/50 [00:41<00:00,  1.22it/s, accurac\r\n",
      "Validating mobilenet_v2 Epoch 6/10: 100%|█| 13/13 [00:07<00:00,  1.78it/s, accur\r\n",
      "mobilenet_v2 Epoch 6/10, Train Loss: 0.0066, Train Acc: 100.00%, Val Loss: 0.0804, Val Acc: 97.50%\r\n",
      "Training mobilenet_v2 Epoch 7/10: 100%|█| 50/50 [00:41<00:00,  1.21it/s, accurac\r\n",
      "Validating mobilenet_v2 Epoch 7/10: 100%|█| 13/13 [00:07<00:00,  1.77it/s, accur\r\n",
      "mobilenet_v2 Epoch 7/10, Train Loss: 0.0134, Train Acc: 99.44%, Val Loss: 0.0534, Val Acc: 98.75%\r\n",
      "Best model for mobilenet_v2 saved with Val Acc: 98.75%\r\n",
      "Training mobilenet_v2 Epoch 8/10: 100%|█| 50/50 [00:41<00:00,  1.22it/s, accurac\r\n",
      "Validating mobilenet_v2 Epoch 8/10: 100%|█| 13/13 [00:07<00:00,  1.71it/s, accur\r\n",
      "mobilenet_v2 Epoch 8/10, Train Loss: 0.0137, Train Acc: 99.38%, Val Loss: 0.0781, Val Acc: 98.25%\r\n",
      "Training mobilenet_v2 Epoch 9/10: 100%|█| 50/50 [00:41<00:00,  1.21it/s, accurac\r\n",
      "Validating mobilenet_v2 Epoch 9/10: 100%|█| 13/13 [00:07<00:00,  1.77it/s, accur\r\n",
      "mobilenet_v2 Epoch 9/10, Train Loss: 0.0042, Train Acc: 99.94%, Val Loss: 0.0865, Val Acc: 98.00%\r\n",
      "Training mobilenet_v2 Epoch 10/10: 100%|█| 50/50 [00:41<00:00,  1.22it/s, accura\r\n",
      "Validating mobilenet_v2 Epoch 10/10: 100%|█| 13/13 [00:07<00:00,  1.72it/s, accu\r\n",
      "mobilenet_v2 Epoch 10/10, Train Loss: 0.0038, Train Acc: 99.94%, Val Loss: 0.0891, Val Acc: 97.50%\r\n",
      "/kaggle/input/ml-ass/nn_models.py:215: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\r\n",
      "  model.load_state_dict(torch.load(f\"best_{model_name}_model.pth\"))\r\n",
      "Classification Report for train mobilenet_v2:\r\n",
      "               precision    recall  f1-score   support\r\n",
      "\r\n",
      "           0     1.0000    1.0000    1.0000       400\r\n",
      "           1     1.0000    0.9975    0.9987       400\r\n",
      "           2     0.9975    1.0000    0.9988       400\r\n",
      "           3     1.0000    1.0000    1.0000       400\r\n",
      "\r\n",
      "    accuracy                         0.9994      1600\r\n",
      "   macro avg     0.9994    0.9994    0.9994      1600\r\n",
      "weighted avg     0.9994    0.9994    0.9994      1600\r\n",
      "\r\n",
      "Train F1 Score for mobilenet_v2: 0.9994\r\n",
      "Classification Report for valmobilenet_v2:\r\n",
      "               precision    recall  f1-score   support\r\n",
      "\r\n",
      "           0     0.9901    1.0000    0.9950       100\r\n",
      "           1     0.9900    0.9900    0.9900       100\r\n",
      "           2     0.9706    0.9900    0.9802       100\r\n",
      "           3     1.0000    0.9700    0.9848       100\r\n",
      "\r\n",
      "    accuracy                         0.9875       400\r\n",
      "   macro avg     0.9877    0.9875    0.9875       400\r\n",
      "weighted avg     0.9877    0.9875    0.9875       400\r\n",
      "\r\n",
      "Training efficientnet_b0 model\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\r\n",
      "100%|███████████████████████████████████████| 20.5M/20.5M [00:00<00:00, 162MB/s]\r\n",
      "cuda\r\n",
      "Total parameters: 4,665,472\r\n",
      "Training efficientnet_b0 Epoch 1/10: 100%|█| 50/50 [00:41<00:00,  1.21it/s, accu\r\n",
      "Validating efficientnet_b0 Epoch 1/10: 100%|█| 13/13 [00:07<00:00,  1.79it/s, ac\r\n",
      "efficientnet_b0 Epoch 1/10, Train Loss: 0.8502, Train Acc: 81.00%, Val Loss: 0.2066, Val Acc: 97.00%\r\n",
      "Best model for efficientnet_b0 saved with Val Acc: 97.00%\r\n",
      "Training efficientnet_b0 Epoch 2/10: 100%|█| 50/50 [00:42<00:00,  1.19it/s, accu\r\n",
      "Validating efficientnet_b0 Epoch 2/10: 100%|█| 13/13 [00:07<00:00,  1.80it/s, ac\r\n",
      "efficientnet_b0 Epoch 2/10, Train Loss: 0.1527, Train Acc: 96.12%, Val Loss: 0.1100, Val Acc: 96.50%\r\n",
      "Training efficientnet_b0 Epoch 3/10: 100%|█| 50/50 [00:41<00:00,  1.20it/s, accu\r\n",
      "Validating efficientnet_b0 Epoch 3/10: 100%|█| 13/13 [00:07<00:00,  1.80it/s, ac\r\n",
      "efficientnet_b0 Epoch 3/10, Train Loss: 0.0581, Train Acc: 98.69%, Val Loss: 0.0891, Val Acc: 97.00%\r\n",
      "Training efficientnet_b0 Epoch 4/10: 100%|█| 50/50 [00:42<00:00,  1.19it/s, accu\r\n",
      "Validating efficientnet_b0 Epoch 4/10: 100%|█| 13/13 [00:07<00:00,  1.80it/s, ac\r\n",
      "efficientnet_b0 Epoch 4/10, Train Loss: 0.0339, Train Acc: 99.06%, Val Loss: 0.0816, Val Acc: 97.50%\r\n",
      "Best model for efficientnet_b0 saved with Val Acc: 97.50%\r\n",
      "Training efficientnet_b0 Epoch 5/10: 100%|█| 50/50 [00:41<00:00,  1.19it/s, accu\r\n",
      "Validating efficientnet_b0 Epoch 5/10: 100%|█| 13/13 [00:07<00:00,  1.80it/s, ac\r\n",
      "efficientnet_b0 Epoch 5/10, Train Loss: 0.0231, Train Acc: 99.38%, Val Loss: 0.0946, Val Acc: 96.75%\r\n",
      "Training efficientnet_b0 Epoch 6/10: 100%|█| 50/50 [00:42<00:00,  1.19it/s, accu\r\n",
      "Validating efficientnet_b0 Epoch 6/10: 100%|█| 13/13 [00:07<00:00,  1.79it/s, ac\r\n",
      "efficientnet_b0 Epoch 6/10, Train Loss: 0.0157, Train Acc: 99.62%, Val Loss: 0.1158, Val Acc: 95.75%\r\n",
      "Training efficientnet_b0 Epoch 7/10: 100%|█| 50/50 [00:41<00:00,  1.20it/s, accu\r\n",
      "Validating efficientnet_b0 Epoch 7/10: 100%|█| 13/13 [00:07<00:00,  1.77it/s, ac\r\n",
      "efficientnet_b0 Epoch 7/10, Train Loss: 0.0165, Train Acc: 99.50%, Val Loss: 0.1112, Val Acc: 96.50%\r\n",
      "Training efficientnet_b0 Epoch 8/10: 100%|█| 50/50 [00:41<00:00,  1.20it/s, accu\r\n",
      "Validating efficientnet_b0 Epoch 8/10: 100%|█| 13/13 [00:07<00:00,  1.79it/s, ac\r\n",
      "efficientnet_b0 Epoch 8/10, Train Loss: 0.0138, Train Acc: 99.62%, Val Loss: 0.1074, Val Acc: 97.25%\r\n",
      "Training efficientnet_b0 Epoch 9/10: 100%|█| 50/50 [00:41<00:00,  1.20it/s, accu\r\n",
      "Validating efficientnet_b0 Epoch 9/10: 100%|█| 13/13 [00:07<00:00,  1.75it/s, ac\r\n",
      "efficientnet_b0 Epoch 9/10, Train Loss: 0.0081, Train Acc: 99.81%, Val Loss: 0.1053, Val Acc: 96.75%\r\n",
      "Training efficientnet_b0 Epoch 10/10: 100%|█| 50/50 [00:41<00:00,  1.21it/s, acc\r\n",
      "Validating efficientnet_b0 Epoch 10/10: 100%|█| 13/13 [00:07<00:00,  1.78it/s, a\r\n",
      "efficientnet_b0 Epoch 10/10, Train Loss: 0.0042, Train Acc: 99.94%, Val Loss: 0.1020, Val Acc: 96.25%\r\n",
      "/kaggle/input/ml-ass/nn_models.py:215: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\r\n",
      "  model.load_state_dict(torch.load(f\"best_{model_name}_model.pth\"))\r\n",
      "Classification Report for train efficientnet_b0:\r\n",
      "               precision    recall  f1-score   support\r\n",
      "\r\n",
      "           0     0.9975    1.0000    0.9988       400\r\n",
      "           1     1.0000    0.9975    0.9987       400\r\n",
      "           2     1.0000    1.0000    1.0000       400\r\n",
      "           3     1.0000    1.0000    1.0000       400\r\n",
      "\r\n",
      "    accuracy                         0.9994      1600\r\n",
      "   macro avg     0.9994    0.9994    0.9994      1600\r\n",
      "weighted avg     0.9994    0.9994    0.9994      1600\r\n",
      "\r\n",
      "Train F1 Score for efficientnet_b0: 0.9994\r\n",
      "Classification Report for valefficientnet_b0:\r\n",
      "               precision    recall  f1-score   support\r\n",
      "\r\n",
      "           0     0.9709    1.0000    0.9852       100\r\n",
      "           1     0.9524    1.0000    0.9756       100\r\n",
      "           2     0.9897    0.9600    0.9746       100\r\n",
      "           3     0.9895    0.9400    0.9641       100\r\n",
      "\r\n",
      "    accuracy                         0.9750       400\r\n",
      "   macro avg     0.9756    0.9750    0.9749       400\r\n",
      "weighted avg     0.9756    0.9750    0.9749       400\r\n",
      "\r\n",
      "Training resnet18 model\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\r\n",
      "100%|██████████████████████████████████████| 44.7M/44.7M [00:00<00:00, 70.7MB/s]\r\n",
      "cuda\r\n",
      "Total parameters: 11,441,220\r\n",
      "Training resnet18 Epoch 1/10: 100%|█| 50/50 [00:41<00:00,  1.22it/s, accuracy=88\r\n",
      "Validating resnet18 Epoch 1/10: 100%|█| 13/13 [00:07<00:00,  1.73it/s, accuracy=\r\n",
      "resnet18 Epoch 1/10, Train Loss: 0.4084, Train Acc: 88.44%, Val Loss: 0.1096, Val Acc: 98.00%\r\n",
      "Best model for resnet18 saved with Val Acc: 98.00%\r\n",
      "Training resnet18 Epoch 2/10: 100%|█| 50/50 [00:40<00:00,  1.23it/s, accuracy=98\r\n",
      "Validating resnet18 Epoch 2/10: 100%|█| 13/13 [00:07<00:00,  1.73it/s, accuracy=\r\n",
      "resnet18 Epoch 2/10, Train Loss: 0.0533, Train Acc: 98.75%, Val Loss: 0.1161, Val Acc: 97.25%\r\n",
      "Training resnet18 Epoch 3/10: 100%|█| 50/50 [00:40<00:00,  1.23it/s, accuracy=99\r\n",
      "Validating resnet18 Epoch 3/10: 100%|█| 13/13 [00:07<00:00,  1.75it/s, accuracy=\r\n",
      "resnet18 Epoch 3/10, Train Loss: 0.0239, Train Acc: 99.50%, Val Loss: 0.1087, Val Acc: 97.00%\r\n",
      "Training resnet18 Epoch 4/10: 100%|█| 50/50 [00:40<00:00,  1.23it/s, accuracy=99\r\n",
      "Validating resnet18 Epoch 4/10: 100%|█| 13/13 [00:07<00:00,  1.71it/s, accuracy=\r\n",
      "resnet18 Epoch 4/10, Train Loss: 0.0109, Train Acc: 99.81%, Val Loss: 0.1117, Val Acc: 97.50%\r\n",
      "Training resnet18 Epoch 5/10: 100%|█| 50/50 [00:40<00:00,  1.24it/s, accuracy=99\r\n",
      "Validating resnet18 Epoch 5/10: 100%|█| 13/13 [00:07<00:00,  1.77it/s, accuracy=\r\n",
      "resnet18 Epoch 5/10, Train Loss: 0.0148, Train Acc: 99.56%, Val Loss: 0.1370, Val Acc: 96.75%\r\n",
      "Training resnet18 Epoch 6/10: 100%|█| 50/50 [00:40<00:00,  1.24it/s, accuracy=99\r\n",
      "Validating resnet18 Epoch 6/10: 100%|█| 13/13 [00:07<00:00,  1.70it/s, accuracy=\r\n",
      "resnet18 Epoch 6/10, Train Loss: 0.0320, Train Acc: 99.12%, Val Loss: 0.1402, Val Acc: 96.00%\r\n",
      "Training resnet18 Epoch 7/10: 100%|█| 50/50 [00:40<00:00,  1.24it/s, accuracy=98\r\n",
      "Validating resnet18 Epoch 7/10: 100%|█| 13/13 [00:07<00:00,  1.76it/s, accuracy=\r\n",
      "resnet18 Epoch 7/10, Train Loss: 0.0458, Train Acc: 98.44%, Val Loss: 0.1048, Val Acc: 97.00%\r\n",
      "Training resnet18 Epoch 8/10: 100%|█| 50/50 [00:40<00:00,  1.25it/s, accuracy=99\r\n",
      "Validating resnet18 Epoch 8/10: 100%|█| 13/13 [00:07<00:00,  1.76it/s, accuracy=\r\n",
      "resnet18 Epoch 8/10, Train Loss: 0.0149, Train Acc: 99.56%, Val Loss: 0.0983, Val Acc: 98.25%\r\n",
      "Best model for resnet18 saved with Val Acc: 98.25%\r\n",
      "Training resnet18 Epoch 9/10: 100%|█| 50/50 [00:39<00:00,  1.26it/s, accuracy=99\r\n",
      "Validating resnet18 Epoch 9/10: 100%|█| 13/13 [00:07<00:00,  1.77it/s, accuracy=\r\n",
      "resnet18 Epoch 9/10, Train Loss: 0.0138, Train Acc: 99.56%, Val Loss: 0.1264, Val Acc: 96.75%\r\n",
      "Training resnet18 Epoch 10/10: 100%|█| 50/50 [00:39<00:00,  1.26it/s, accuracy=9\r\n",
      "Validating resnet18 Epoch 10/10: 100%|█| 13/13 [00:07<00:00,  1.73it/s, accuracy\r\n",
      "resnet18 Epoch 10/10, Train Loss: 0.0074, Train Acc: 99.81%, Val Loss: 0.0770, Val Acc: 97.75%\r\n",
      "/kaggle/input/ml-ass/nn_models.py:215: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\r\n",
      "  model.load_state_dict(torch.load(f\"best_{model_name}_model.pth\"))\r\n",
      "Classification Report for train resnet18:\r\n",
      "               precision    recall  f1-score   support\r\n",
      "\r\n",
      "           0     1.0000    1.0000    1.0000       400\r\n",
      "           1     1.0000    1.0000    1.0000       400\r\n",
      "           2     1.0000    1.0000    1.0000       400\r\n",
      "           3     1.0000    1.0000    1.0000       400\r\n",
      "\r\n",
      "    accuracy                         1.0000      1600\r\n",
      "   macro avg     1.0000    1.0000    1.0000      1600\r\n",
      "weighted avg     1.0000    1.0000    1.0000      1600\r\n",
      "\r\n",
      "Train F1 Score for resnet18: 1.0000\r\n",
      "Classification Report for valresnet18:\r\n",
      "               precision    recall  f1-score   support\r\n",
      "\r\n",
      "           0     0.9709    1.0000    0.9852       100\r\n",
      "           1     0.9802    0.9900    0.9851       100\r\n",
      "           2     0.9800    0.9800    0.9800       100\r\n",
      "           3     1.0000    0.9600    0.9796       100\r\n",
      "\r\n",
      "    accuracy                         0.9825       400\r\n",
      "   macro avg     0.9828    0.9825    0.9825       400\r\n",
      "weighted avg     0.9828    0.9825    0.9825       400\r\n",
      "\r\n",
      "Training alexnet model\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\r\n",
      "100%|█████████████████████████████████████████| 233M/233M [00:01<00:00, 198MB/s]\r\n",
      "cuda\r\n",
      "Total parameters: 59,103,556\r\n",
      "Training alexnet Epoch 1/10: 100%|█| 50/50 [00:37<00:00,  1.33it/s, accuracy=88.\r\n",
      "Validating alexnet Epoch 1/10: 100%|█| 13/13 [00:07<00:00,  1.79it/s, accuracy=9\r\n",
      "alexnet Epoch 1/10, Train Loss: 0.3263, Train Acc: 88.62%, Val Loss: 0.1292, Val Acc: 95.25%\r\n",
      "Best model for alexnet saved with Val Acc: 95.25%\r\n",
      "Training alexnet Epoch 2/10: 100%|█| 50/50 [00:37<00:00,  1.33it/s, accuracy=97.\r\n",
      "Validating alexnet Epoch 2/10: 100%|█| 13/13 [00:07<00:00,  1.78it/s, accuracy=9\r\n",
      "alexnet Epoch 2/10, Train Loss: 0.0841, Train Acc: 97.25%, Val Loss: 0.1510, Val Acc: 96.25%\r\n",
      "Best model for alexnet saved with Val Acc: 96.25%\r\n",
      "Training alexnet Epoch 3/10: 100%|█| 50/50 [00:37<00:00,  1.33it/s, accuracy=97.\r\n",
      "Validating alexnet Epoch 3/10: 100%|█| 13/13 [00:06<00:00,  1.87it/s, accuracy=9\r\n",
      "alexnet Epoch 3/10, Train Loss: 0.0673, Train Acc: 97.44%, Val Loss: 0.1293, Val Acc: 96.25%\r\n",
      "Training alexnet Epoch 4/10: 100%|█| 50/50 [00:37<00:00,  1.34it/s, accuracy=98.\r\n",
      "Validating alexnet Epoch 4/10: 100%|█| 13/13 [00:06<00:00,  1.86it/s, accuracy=9\r\n",
      "alexnet Epoch 4/10, Train Loss: 0.0223, Train Acc: 98.94%, Val Loss: 0.1689, Val Acc: 95.75%\r\n",
      "Training alexnet Epoch 5/10: 100%|█| 50/50 [00:37<00:00,  1.34it/s, accuracy=99.\r\n",
      "Validating alexnet Epoch 5/10: 100%|█| 13/13 [00:06<00:00,  1.88it/s, accuracy=9\r\n",
      "alexnet Epoch 5/10, Train Loss: 0.0075, Train Acc: 99.88%, Val Loss: 0.1501, Val Acc: 97.25%\r\n",
      "Best model for alexnet saved with Val Acc: 97.25%\r\n",
      "Training alexnet Epoch 6/10: 100%|█| 50/50 [00:37<00:00,  1.34it/s, accuracy=99.\r\n",
      "Validating alexnet Epoch 6/10: 100%|█| 13/13 [00:07<00:00,  1.85it/s, accuracy=9\r\n",
      "alexnet Epoch 6/10, Train Loss: 0.0029, Train Acc: 99.94%, Val Loss: 0.1511, Val Acc: 96.50%\r\n",
      "Training alexnet Epoch 7/10: 100%|█| 50/50 [00:37<00:00,  1.33it/s, accuracy=99.\r\n",
      "Validating alexnet Epoch 7/10: 100%|█| 13/13 [00:07<00:00,  1.79it/s, accuracy=9\r\n",
      "alexnet Epoch 7/10, Train Loss: 0.0345, Train Acc: 99.19%, Val Loss: 0.1100, Val Acc: 97.00%\r\n",
      "Training alexnet Epoch 8/10: 100%|█| 50/50 [00:37<00:00,  1.35it/s, accuracy=96.\r\n",
      "Validating alexnet Epoch 8/10: 100%|█| 13/13 [00:07<00:00,  1.84it/s, accuracy=9\r\n",
      "alexnet Epoch 8/10, Train Loss: 0.0865, Train Acc: 96.94%, Val Loss: 0.1510, Val Acc: 96.25%\r\n",
      "Training alexnet Epoch 9/10: 100%|█| 50/50 [00:37<00:00,  1.34it/s, accuracy=99.\r\n",
      "Validating alexnet Epoch 9/10: 100%|█| 13/13 [00:07<00:00,  1.76it/s, accuracy=9\r\n",
      "alexnet Epoch 9/10, Train Loss: 0.0213, Train Acc: 99.50%, Val Loss: 0.1399, Val Acc: 96.00%\r\n",
      "Training alexnet Epoch 10/10: 100%|█| 50/50 [00:37<00:00,  1.33it/s, accuracy=10\r\n",
      "Validating alexnet Epoch 10/10: 100%|█| 13/13 [00:07<00:00,  1.86it/s, accuracy=\r\n",
      "alexnet Epoch 10/10, Train Loss: 0.0027, Train Acc: 100.00%, Val Loss: 0.1102, Val Acc: 97.25%\r\n",
      "/kaggle/input/ml-ass/nn_models.py:215: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\r\n",
      "  model.load_state_dict(torch.load(f\"best_{model_name}_model.pth\"))\r\n",
      "Classification Report for train alexnet:\r\n",
      "               precision    recall  f1-score   support\r\n",
      "\r\n",
      "           0     1.0000    1.0000    1.0000       400\r\n",
      "           1     1.0000    1.0000    1.0000       400\r\n",
      "           2     1.0000    1.0000    1.0000       400\r\n",
      "           3     1.0000    1.0000    1.0000       400\r\n",
      "\r\n",
      "    accuracy                         1.0000      1600\r\n",
      "   macro avg     1.0000    1.0000    1.0000      1600\r\n",
      "weighted avg     1.0000    1.0000    1.0000      1600\r\n",
      "\r\n",
      "Train F1 Score for alexnet: 1.0000\r\n",
      "Classification Report for valalexnet:\r\n",
      "               precision    recall  f1-score   support\r\n",
      "\r\n",
      "           0     0.9524    1.0000    0.9756       100\r\n",
      "           1     0.9703    0.9800    0.9751       100\r\n",
      "           2     0.9798    0.9700    0.9749       100\r\n",
      "           3     0.9895    0.9400    0.9641       100\r\n",
      "\r\n",
      "    accuracy                         0.9725       400\r\n",
      "   macro avg     0.9730    0.9725    0.9724       400\r\n",
      "weighted avg     0.9730    0.9725    0.9724       400\r\n",
      "\r\n",
      "Training squeezenet1_0 model\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_0_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_0_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Downloading: \"https://download.pytorch.org/models/squeezenet1_0-b66bff10.pth\" to /root/.cache/torch/hub/checkpoints/squeezenet1_0-b66bff10.pth\r\n",
      "100%|██████████████████████████████████████| 4.78M/4.78M [00:00<00:00, 67.5MB/s]\r\n",
      "cuda\r\n",
      "Total parameters: 737,476\r\n",
      "Training squeezenet1_0 Epoch 1/10: 100%|█| 50/50 [00:39<00:00,  1.25it/s, accura\r\n",
      "Validating squeezenet1_0 Epoch 1/10: 100%|█| 13/13 [00:07<00:00,  1.68it/s, accu\r\n",
      "squeezenet1_0 Epoch 1/10, Train Loss: 0.4524, Train Acc: 82.31%, Val Loss: 0.2243, Val Acc: 93.75%\r\n",
      "Best model for squeezenet1_0 saved with Val Acc: 93.75%\r\n",
      "Training squeezenet1_0 Epoch 2/10: 100%|█| 50/50 [00:39<00:00,  1.25it/s, accura\r\n",
      "Validating squeezenet1_0 Epoch 2/10: 100%|█| 13/13 [00:07<00:00,  1.78it/s, accu\r\n",
      "squeezenet1_0 Epoch 2/10, Train Loss: 0.1352, Train Acc: 95.62%, Val Loss: 0.1620, Val Acc: 94.50%\r\n",
      "Best model for squeezenet1_0 saved with Val Acc: 94.50%\r\n",
      "Training squeezenet1_0 Epoch 3/10: 100%|█| 50/50 [00:40<00:00,  1.25it/s, accura\r\n",
      "Validating squeezenet1_0 Epoch 3/10: 100%|█| 13/13 [00:07<00:00,  1.70it/s, accu\r\n",
      "squeezenet1_0 Epoch 3/10, Train Loss: 0.1102, Train Acc: 95.81%, Val Loss: 0.1621, Val Acc: 93.25%\r\n",
      "Training squeezenet1_0 Epoch 4/10: 100%|█| 50/50 [00:40<00:00,  1.25it/s, accura\r\n",
      "Validating squeezenet1_0 Epoch 4/10: 100%|█| 13/13 [00:07<00:00,  1.72it/s, accu\r\n",
      "squeezenet1_0 Epoch 4/10, Train Loss: 0.0869, Train Acc: 97.19%, Val Loss: 0.1479, Val Acc: 94.00%\r\n",
      "Training squeezenet1_0 Epoch 5/10: 100%|█| 50/50 [00:39<00:00,  1.25it/s, accura\r\n",
      "Validating squeezenet1_0 Epoch 5/10: 100%|█| 13/13 [00:07<00:00,  1.74it/s, accu\r\n",
      "squeezenet1_0 Epoch 5/10, Train Loss: 0.0581, Train Acc: 98.19%, Val Loss: 0.1216, Val Acc: 94.25%\r\n",
      "Training squeezenet1_0 Epoch 6/10: 100%|█| 50/50 [00:40<00:00,  1.24it/s, accura\r\n",
      "Validating squeezenet1_0 Epoch 6/10: 100%|█| 13/13 [00:07<00:00,  1.77it/s, accu\r\n",
      "squeezenet1_0 Epoch 6/10, Train Loss: 0.0509, Train Acc: 97.94%, Val Loss: 0.1570, Val Acc: 94.75%\r\n",
      "Best model for squeezenet1_0 saved with Val Acc: 94.75%\r\n",
      "Training squeezenet1_0 Epoch 7/10: 100%|█| 50/50 [00:40<00:00,  1.25it/s, accura\r\n",
      "Validating squeezenet1_0 Epoch 7/10: 100%|█| 13/13 [00:07<00:00,  1.72it/s, accu\r\n",
      "squeezenet1_0 Epoch 7/10, Train Loss: 0.0480, Train Acc: 98.50%, Val Loss: 0.0950, Val Acc: 96.25%\r\n",
      "Best model for squeezenet1_0 saved with Val Acc: 96.25%\r\n",
      "Training squeezenet1_0 Epoch 8/10: 100%|█| 50/50 [00:40<00:00,  1.24it/s, accura\r\n",
      "Validating squeezenet1_0 Epoch 8/10: 100%|█| 13/13 [00:07<00:00,  1.77it/s, accu\r\n",
      "squeezenet1_0 Epoch 8/10, Train Loss: 0.0260, Train Acc: 99.31%, Val Loss: 0.1786, Val Acc: 95.25%\r\n",
      "Training squeezenet1_0 Epoch 9/10: 100%|█| 50/50 [00:40<00:00,  1.25it/s, accura\r\n",
      "Validating squeezenet1_0 Epoch 9/10: 100%|█| 13/13 [00:07<00:00,  1.64it/s, accu\r\n",
      "squeezenet1_0 Epoch 9/10, Train Loss: 0.0293, Train Acc: 98.94%, Val Loss: 0.1196, Val Acc: 96.50%\r\n",
      "Best model for squeezenet1_0 saved with Val Acc: 96.50%\r\n",
      "Training squeezenet1_0 Epoch 10/10: 100%|█| 50/50 [00:40<00:00,  1.24it/s, accur\r\n",
      "Validating squeezenet1_0 Epoch 10/10: 100%|█| 13/13 [00:07<00:00,  1.74it/s, acc\r\n",
      "squeezenet1_0 Epoch 10/10, Train Loss: 0.0177, Train Acc: 99.56%, Val Loss: 0.1328, Val Acc: 97.50%\r\n",
      "Best model for squeezenet1_0 saved with Val Acc: 97.50%\r\n",
      "/kaggle/input/ml-ass/nn_models.py:215: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\r\n",
      "  model.load_state_dict(torch.load(f\"best_{model_name}_model.pth\"))\r\n",
      "Classification Report for train squeezenet1_0:\r\n",
      "               precision    recall  f1-score   support\r\n",
      "\r\n",
      "           0     1.0000    1.0000    1.0000       400\r\n",
      "           1     1.0000    1.0000    1.0000       400\r\n",
      "           2     1.0000    1.0000    1.0000       400\r\n",
      "           3     1.0000    1.0000    1.0000       400\r\n",
      "\r\n",
      "    accuracy                         1.0000      1600\r\n",
      "   macro avg     1.0000    1.0000    1.0000      1600\r\n",
      "weighted avg     1.0000    1.0000    1.0000      1600\r\n",
      "\r\n",
      "Train F1 Score for squeezenet1_0: 1.0000\r\n",
      "Classification Report for valsqueezenet1_0:\r\n",
      "               precision    recall  f1-score   support\r\n",
      "\r\n",
      "           0     0.9524    1.0000    0.9756       100\r\n",
      "           1     0.9615    1.0000    0.9804       100\r\n",
      "           2     1.0000    0.9600    0.9796       100\r\n",
      "           3     0.9895    0.9400    0.9641       100\r\n",
      "\r\n",
      "    accuracy                         0.9750       400\r\n",
      "   macro avg     0.9758    0.9750    0.9749       400\r\n",
      "weighted avg     0.9758    0.9750    0.9749       400\r\n",
      "\r\n",
      "Training shufflenet_v2_x1_0 model\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ShuffleNet_V2_X1_0_Weights.IMAGENET1K_V1`. You can also use `weights=ShuffleNet_V2_X1_0_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Downloading: \"https://download.pytorch.org/models/shufflenetv2_x1-5666bf0f80.pth\" to /root/.cache/torch/hub/checkpoints/shufflenetv2_x1-5666bf0f80.pth\r\n",
      "100%|██████████████████████████████████████| 8.79M/8.79M [00:00<00:00, 70.3MB/s]\r\n",
      "cuda\r\n",
      "Total parameters: 1,780,456\r\n",
      "Training shufflenet_v2_x1_0 Epoch 1/10: 100%|█| 50/50 [00:37<00:00,  1.32it/s, a\r\n",
      "Validating shufflenet_v2_x1_0 Epoch 1/10: 100%|█| 13/13 [00:06<00:00,  1.88it/s,\r\n",
      "shufflenet_v2_x1_0 Epoch 1/10, Train Loss: 1.3219, Train Acc: 62.62%, Val Loss: 1.1529, Val Acc: 88.25%\r\n",
      "Best model for shufflenet_v2_x1_0 saved with Val Acc: 88.25%\r\n",
      "Training shufflenet_v2_x1_0 Epoch 2/10: 100%|█| 50/50 [00:37<00:00,  1.33it/s, a\r\n",
      "Validating shufflenet_v2_x1_0 Epoch 2/10: 100%|█| 13/13 [00:07<00:00,  1.86it/s,\r\n",
      "shufflenet_v2_x1_0 Epoch 2/10, Train Loss: 0.8772, Train Acc: 90.62%, Val Loss: 0.4533, Val Acc: 94.75%\r\n",
      "Best model for shufflenet_v2_x1_0 saved with Val Acc: 94.75%\r\n",
      "Training shufflenet_v2_x1_0 Epoch 3/10: 100%|█| 50/50 [00:37<00:00,  1.33it/s, a\r\n",
      "Validating shufflenet_v2_x1_0 Epoch 3/10: 100%|█| 13/13 [00:07<00:00,  1.79it/s,\r\n",
      "shufflenet_v2_x1_0 Epoch 3/10, Train Loss: 0.3344, Train Acc: 95.12%, Val Loss: 0.1844, Val Acc: 97.00%\r\n",
      "Best model for shufflenet_v2_x1_0 saved with Val Acc: 97.00%\r\n",
      "Training shufflenet_v2_x1_0 Epoch 4/10: 100%|█| 50/50 [00:37<00:00,  1.33it/s, a\r\n",
      "Validating shufflenet_v2_x1_0 Epoch 4/10: 100%|█| 13/13 [00:06<00:00,  1.89it/s,\r\n",
      "shufflenet_v2_x1_0 Epoch 4/10, Train Loss: 0.1794, Train Acc: 96.19%, Val Loss: 0.1208, Val Acc: 97.25%\r\n",
      "Best model for shufflenet_v2_x1_0 saved with Val Acc: 97.25%\r\n",
      "Training shufflenet_v2_x1_0 Epoch 5/10: 100%|█| 50/50 [00:37<00:00,  1.33it/s, a\r\n",
      "Validating shufflenet_v2_x1_0 Epoch 5/10: 100%|█| 13/13 [00:06<00:00,  1.88it/s,\r\n",
      "shufflenet_v2_x1_0 Epoch 5/10, Train Loss: 0.0914, Train Acc: 98.25%, Val Loss: 0.0998, Val Acc: 97.00%\r\n",
      "Training shufflenet_v2_x1_0 Epoch 6/10: 100%|█| 50/50 [00:37<00:00,  1.32it/s, a\r\n",
      "Validating shufflenet_v2_x1_0 Epoch 6/10: 100%|█| 13/13 [00:07<00:00,  1.85it/s,\r\n",
      "shufflenet_v2_x1_0 Epoch 6/10, Train Loss: 0.0509, Train Acc: 99.06%, Val Loss: 0.0936, Val Acc: 97.00%\r\n",
      "Training shufflenet_v2_x1_0 Epoch 7/10: 100%|█| 50/50 [00:37<00:00,  1.33it/s, a\r\n",
      "Validating shufflenet_v2_x1_0 Epoch 7/10: 100%|█| 13/13 [00:07<00:00,  1.82it/s,\r\n",
      "shufflenet_v2_x1_0 Epoch 7/10, Train Loss: 0.0449, Train Acc: 98.94%, Val Loss: 0.0850, Val Acc: 97.25%\r\n",
      "Training shufflenet_v2_x1_0 Epoch 8/10: 100%|█| 50/50 [00:37<00:00,  1.33it/s, a\r\n",
      "Validating shufflenet_v2_x1_0 Epoch 8/10: 100%|█| 13/13 [00:07<00:00,  1.81it/s,\r\n",
      "shufflenet_v2_x1_0 Epoch 8/10, Train Loss: 0.0253, Train Acc: 99.50%, Val Loss: 0.0855, Val Acc: 97.25%\r\n",
      "Training shufflenet_v2_x1_0 Epoch 9/10: 100%|█| 50/50 [00:38<00:00,  1.31it/s, a\r\n",
      "Validating shufflenet_v2_x1_0 Epoch 9/10: 100%|█| 13/13 [00:07<00:00,  1.85it/s,\r\n",
      "shufflenet_v2_x1_0 Epoch 9/10, Train Loss: 0.0403, Train Acc: 99.19%, Val Loss: 0.0857, Val Acc: 97.25%\r\n",
      "Training shufflenet_v2_x1_0 Epoch 10/10: 100%|█| 50/50 [00:37<00:00,  1.32it/s, \r\n",
      "Validating shufflenet_v2_x1_0 Epoch 10/10: 100%|█| 13/13 [00:06<00:00,  1.89it/s\r\n",
      "shufflenet_v2_x1_0 Epoch 10/10, Train Loss: 0.0209, Train Acc: 99.62%, Val Loss: 0.0957, Val Acc: 97.25%\r\n",
      "/kaggle/input/ml-ass/nn_models.py:215: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\r\n",
      "  model.load_state_dict(torch.load(f\"best_{model_name}_model.pth\"))\r\n",
      "Classification Report for train shufflenet_v2_x1_0:\r\n",
      "               precision    recall  f1-score   support\r\n",
      "\r\n",
      "           0     0.9975    1.0000    0.9988       400\r\n",
      "           1     1.0000    0.9800    0.9899       400\r\n",
      "           2     0.9803    0.9975    0.9888       400\r\n",
      "           3     1.0000    1.0000    1.0000       400\r\n",
      "\r\n",
      "    accuracy                         0.9944      1600\r\n",
      "   macro avg     0.9945    0.9944    0.9944      1600\r\n",
      "weighted avg     0.9945    0.9944    0.9944      1600\r\n",
      "\r\n",
      "Train F1 Score for shufflenet_v2_x1_0: 0.9944\r\n",
      "Classification Report for valshufflenet_v2_x1_0:\r\n",
      "               precision    recall  f1-score   support\r\n",
      "\r\n",
      "           0     0.9804    1.0000    0.9901       100\r\n",
      "           1     0.9346    1.0000    0.9662       100\r\n",
      "           2     1.0000    0.9200    0.9583       100\r\n",
      "           3     0.9798    0.9700    0.9749       100\r\n",
      "\r\n",
      "    accuracy                         0.9725       400\r\n",
      "   macro avg     0.9737    0.9725    0.9724       400\r\n",
      "weighted avg     0.9737    0.9725    0.9724       400\r\n",
      "\r\n",
      "Training googlenet model\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Downloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to /root/.cache/torch/hub/checkpoints/googlenet-1378be20.pth\r\n",
      "100%|██████████████████████████████████████| 49.7M/49.7M [00:00<00:00, 89.7MB/s]\r\n",
      "cuda\r\n",
      "Total parameters: 6,126,756\r\n",
      "Training googlenet Epoch 1/10: 100%|█| 50/50 [00:40<00:00,  1.25it/s, accuracy=8\r\n",
      "Validating googlenet Epoch 1/10: 100%|█| 13/13 [00:07<00:00,  1.81it/s, accuracy\r\n",
      "googlenet Epoch 1/10, Train Loss: 0.7120, Train Acc: 81.00%, Val Loss: 0.1646, Val Acc: 95.75%\r\n",
      "Best model for googlenet saved with Val Acc: 95.75%\r\n",
      "Training googlenet Epoch 2/10: 100%|█| 50/50 [00:40<00:00,  1.24it/s, accuracy=9\r\n",
      "Validating googlenet Epoch 2/10: 100%|█| 13/13 [00:07<00:00,  1.72it/s, accuracy\r\n",
      "googlenet Epoch 2/10, Train Loss: 0.1145, Train Acc: 96.94%, Val Loss: 0.1194, Val Acc: 96.25%\r\n",
      "Best model for googlenet saved with Val Acc: 96.25%\r\n",
      "Training googlenet Epoch 3/10: 100%|█| 50/50 [00:40<00:00,  1.24it/s, accuracy=9\r\n",
      "Validating googlenet Epoch 3/10: 100%|█| 13/13 [00:07<00:00,  1.83it/s, accuracy\r\n",
      "googlenet Epoch 3/10, Train Loss: 0.0400, Train Acc: 99.19%, Val Loss: 0.0928, Val Acc: 96.75%\r\n",
      "Best model for googlenet saved with Val Acc: 96.75%\r\n",
      "Training googlenet Epoch 4/10: 100%|█| 50/50 [00:40<00:00,  1.25it/s, accuracy=9\r\n",
      "Validating googlenet Epoch 4/10: 100%|█| 13/13 [00:07<00:00,  1.67it/s, accuracy\r\n",
      "googlenet Epoch 4/10, Train Loss: 0.0218, Train Acc: 99.62%, Val Loss: 0.1038, Val Acc: 96.75%\r\n",
      "Training googlenet Epoch 5/10: 100%|█| 50/50 [00:40<00:00,  1.24it/s, accuracy=9\r\n",
      "Validating googlenet Epoch 5/10: 100%|█| 13/13 [00:07<00:00,  1.82it/s, accuracy\r\n",
      "googlenet Epoch 5/10, Train Loss: 0.0202, Train Acc: 99.56%, Val Loss: 0.1094, Val Acc: 96.75%\r\n",
      "Training googlenet Epoch 6/10: 100%|█| 50/50 [00:40<00:00,  1.25it/s, accuracy=9\r\n",
      "Validating googlenet Epoch 6/10: 100%|█| 13/13 [00:07<00:00,  1.79it/s, accuracy\r\n",
      "googlenet Epoch 6/10, Train Loss: 0.0182, Train Acc: 99.56%, Val Loss: 0.1008, Val Acc: 97.25%\r\n",
      "Best model for googlenet saved with Val Acc: 97.25%\r\n",
      "Training googlenet Epoch 7/10: 100%|█| 50/50 [00:40<00:00,  1.24it/s, accuracy=9\r\n",
      "Validating googlenet Epoch 7/10: 100%|█| 13/13 [00:07<00:00,  1.81it/s, accuracy\r\n",
      "googlenet Epoch 7/10, Train Loss: 0.0126, Train Acc: 99.69%, Val Loss: 0.1060, Val Acc: 97.00%\r\n",
      "Training googlenet Epoch 8/10: 100%|█| 50/50 [00:39<00:00,  1.25it/s, accuracy=1\r\n",
      "Validating googlenet Epoch 8/10: 100%|█| 13/13 [00:07<00:00,  1.79it/s, accuracy\r\n",
      "googlenet Epoch 8/10, Train Loss: 0.0060, Train Acc: 100.00%, Val Loss: 0.1111, Val Acc: 97.25%\r\n",
      "Training googlenet Epoch 9/10: 100%|█| 50/50 [00:39<00:00,  1.25it/s, accuracy=9\r\n",
      "Validating googlenet Epoch 9/10: 100%|█| 13/13 [00:07<00:00,  1.81it/s, accuracy\r\n",
      "googlenet Epoch 9/10, Train Loss: 0.0049, Train Acc: 99.94%, Val Loss: 0.1120, Val Acc: 96.75%\r\n",
      "Training googlenet Epoch 10/10: 100%|█| 50/50 [00:40<00:00,  1.24it/s, accuracy=\r\n",
      "Validating googlenet Epoch 10/10: 100%|█| 13/13 [00:07<00:00,  1.79it/s, accurac\r\n",
      "googlenet Epoch 10/10, Train Loss: 0.0072, Train Acc: 99.88%, Val Loss: 0.1121, Val Acc: 96.50%\r\n",
      "/kaggle/input/ml-ass/nn_models.py:215: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\r\n",
      "  model.load_state_dict(torch.load(f\"best_{model_name}_model.pth\"))\r\n",
      "Classification Report for train googlenet:\r\n",
      "               precision    recall  f1-score   support\r\n",
      "\r\n",
      "           0     1.0000    1.0000    1.0000       400\r\n",
      "           1     1.0000    1.0000    1.0000       400\r\n",
      "           2     1.0000    1.0000    1.0000       400\r\n",
      "           3     1.0000    1.0000    1.0000       400\r\n",
      "\r\n",
      "    accuracy                         1.0000      1600\r\n",
      "   macro avg     1.0000    1.0000    1.0000      1600\r\n",
      "weighted avg     1.0000    1.0000    1.0000      1600\r\n",
      "\r\n",
      "Train F1 Score for googlenet: 1.0000\r\n",
      "Classification Report for valgooglenet:\r\n",
      "               precision    recall  f1-score   support\r\n",
      "\r\n",
      "           0     0.9709    1.0000    0.9852       100\r\n",
      "           1     0.9897    0.9600    0.9746       100\r\n",
      "           2     0.9604    0.9700    0.9652       100\r\n",
      "           3     0.9697    0.9600    0.9648       100\r\n",
      "\r\n",
      "    accuracy                         0.9725       400\r\n",
      "   macro avg     0.9727    0.9725    0.9725       400\r\n",
      "weighted avg     0.9727    0.9725    0.9725       400\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/kaggle/input/ml-ass/main.py\", line 157, in <module>\r\n",
      "    results = train_and_evaluate_nn_models(train_loader, val_loader, device, num_epochs=10)\r\n",
      "  File \"/kaggle/input/ml-ass/main.py\", line 122, in train_and_evaluate_nn_models\r\n",
      "    plot_and_save_results(results)\r\n",
      "  File \"/kaggle/input/ml-ass/main.py\", line 112, in plot_and_save_results\r\n",
      "    plt.plot(epochs, metrics[\"train_f1_scores\"], label='Train F1 Score')\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/matplotlib/pyplot.py\", line 2812, in plot\r\n",
      "    return gca().plot(\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/matplotlib/axes/_axes.py\", line 1688, in plot\r\n",
      "    lines = [*self._get_lines(*args, data=data, **kwargs)]\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/matplotlib/axes/_base.py\", line 311, in __call__\r\n",
      "    yield from self._plot_args(\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/matplotlib/axes/_base.py\", line 504, in _plot_args\r\n",
      "    raise ValueError(f\"x and y must have same first dimension, but \"\r\n",
      "ValueError: x and y must have same first dimension, but have shapes (10,) and (1,)\r\n"
     ]
    }
   ],
   "source": [
    "!python3 /kaggle/input/ml-ass/main.py \"/kaggle/input/disasterclassification/train\" \"/kaggle/input/disasterclassification/validation\" nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "664c91b4",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-24T09:45:49.338683Z",
     "iopub.status.busy": "2024-11-24T09:45:49.337954Z",
     "iopub.status.idle": "2024-11-24T09:46:52.520116Z",
     "shell.execute_reply": "2024-11-24T09:46:52.519258Z"
    },
    "papermill": {
     "duration": 63.598889,
     "end_time": "2024-11-24T09:46:52.522269",
     "exception": false,
     "start_time": "2024-11-24T09:45:48.923380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Using Support Vector Machine Model\r\n",
      "<PIL.Image.Image image mode=RGB size=666x700 at 0x7A982A71E440>\r\n",
      "<PIL.Image.Image image mode=RGB size=480x360 at 0x7A982A71E3E0>\r\n",
      "<PIL.Image.Image image mode=RGB size=900x499 at 0x7A982A71E530>\r\n",
      "<PIL.Image.Image image mode=RGB size=696x522 at 0x7A982A71E5C0>\r\n",
      "<PIL.Image.Image image mode=RGB size=800x518 at 0x7A982A71E740>\r\n",
      "<PIL.Image.Image image mode=RGB size=460x279 at 0x7A982A71E500>\r\n",
      "<PIL.Image.Image image mode=RGB size=992x558 at 0x7A982A71DDB0>\r\n",
      "<PIL.Image.Image image mode=RGB size=1600x1000 at 0x7A982A71E440>\r\n",
      "<PIL.Image.Image image mode=RGB size=2902x1633 at 0x7A982A71E3E0>\r\n",
      "<PIL.Image.Image image mode=RGB size=1500x1000 at 0x7A982A71E530>\r\n",
      "Train Directory: /kaggle/input/disasterclassification/train\r\n",
      "Validation Directory: /kaggle/input/disasterclassification/validation\r\n",
      "Model Type: svm\r\n"
     ]
    }
   ],
   "source": [
    "!python3 /kaggle/input/ml-ass/main.py \"/kaggle/input/disasterclassification/train\" \"/kaggle/input/disasterclassification/validation\" svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b67ed7b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T09:46:53.335273Z",
     "iopub.status.busy": "2024-11-24T09:46:53.334909Z",
     "iopub.status.idle": "2024-11-24T09:47:58.779521Z",
     "shell.execute_reply": "2024-11-24T09:47:58.778265Z"
    },
    "papermill": {
     "duration": 65.858987,
     "end_time": "2024-11-24T09:47:58.781829",
     "exception": false,
     "start_time": "2024-11-24T09:46:52.922842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Using Random Forest Model\r\n",
      "Misclassified images fetching: 100%|████████| 400/400 [00:00<00:00, 1581.09it/s]\r\n",
      "Train Directory: /kaggle/input/disasterclassification/train\r\n",
      "Validation Directory: /kaggle/input/disasterclassification/validation\r\n",
      "Model Type: rf\r\n"
     ]
    }
   ],
   "source": [
    "!python3 /kaggle/input/ml-ass/main.py \"/kaggle/input/disasterclassification/train\" \"/kaggle/input/disasterclassification/validation\" rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd21b7f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T09:47:59.546563Z",
     "iopub.status.busy": "2024-11-24T09:47:59.545835Z",
     "iopub.status.idle": "2024-11-24T09:51:34.446153Z",
     "shell.execute_reply": "2024-11-24T09:51:34.445284Z"
    },
    "papermill": {
     "duration": 215.275987,
     "end_time": "2024-11-24T09:51:34.448364",
     "exception": false,
     "start_time": "2024-11-24T09:47:59.172377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Using AdaBoost Model\r\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\r\n",
      "  warnings.warn(\r\n",
      "Misclassified images fetching: 100%|█████████| 400/400 [00:00<00:00, 578.15it/s]\r\n",
      "Train Directory: /kaggle/input/disasterclassification/train\r\n",
      "Validation Directory: /kaggle/input/disasterclassification/validation\r\n",
      "Model Type: ada\r\n"
     ]
    }
   ],
   "source": [
    "!python3 /kaggle/input/ml-ass/main.py \"/kaggle/input/disasterclassification/train\" \"/kaggle/input/disasterclassification/validation\" ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0846e6",
   "metadata": {
    "papermill": {
     "duration": 0.416484,
     "end_time": "2024-11-24T09:51:35.243733",
     "exception": false,
     "start_time": "2024-11-24T09:51:34.827249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6031130,
     "sourceId": 9833038,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6111744,
     "sourceId": 9997395,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8470.808082,
   "end_time": "2024-11-24T09:51:35.833654",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-24T07:30:25.025572",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
